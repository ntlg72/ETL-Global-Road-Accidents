{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EDA y Carga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de librerías"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del paquete \"connection_db\", ubicado en el directorio \"source del directorio\", se importa el módulo \"db_utils\" que proporciona una funciones centralizada para establecer y gestionar conexiones a una base de datos PostgreSQL. Su objetivo es promover la reutilización de código, la modularidad y la consistencia en el acceso a la base de datos dentro de los diferentes notebooks de este proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from psycopg2 import sql\n",
    "from sqlalchemy import create_engine\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(os.path.abspath('../source'))\n",
    "from connection_db.db_utils import get_connection , close_connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Este fragmento de código establece una conexión a una base de datos PostgreSQL utilizando la función \"get_connection\" del módulo \"connection_db.db_utils\", lee todos los datos de la tabla \"accidents\" en un DataFrame de Pandas, muestra las primeras filas del DataFrame y luego cierra la conexión a la base de datos utilizando la función \"close_connection\" del mismo módulo, para liberar recursos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = get_connection()\n",
    "df = pd.read_sql_query(\"SELECT * FROM accidents\", engine)\n",
    "df.head()\n",
    "close_connection(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tipos de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos analizado se encuentra estructurado en una base de datos con un total de 132,000 registros y 31 columnas. Cada columna representa una variable específica relacionada con el análisis de accidentes de tránsito, abarcando diferentes tipos de datos que incluyen valores numéricos enteros (int64), flotantes (float64), booleanos (bool) y caracteres (object)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_floats = sum(df.dtypes == 'float64')\n",
    "num_ints = sum(df.dtypes == 'int64')\n",
    "num_objects = sum(df.dtypes == 'object')\n",
    "num_bools = sum(df.dtypes == 'bool')\n",
    "\n",
    "print(f\"Columnas de tipo float: {num_floats}\")\n",
    "print(f\"Columnas de tipo integer: {num_ints}\")\n",
    "print(f\"Columnas de tipo object: {num_objects}\")\n",
    "print(f\"Columnas de tipo boolean: {num_bools}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset bajo análisis contiene distintos tipos de datos distribuidos de la siguiente manera:\n",
    "\n",
    "7 columnas de tipo float64: Estas columnas representan variables numéricas de precisión decimal, como niveles de alcohol en sangre, densidad poblacional y condiciones de visibilidad.\n",
    "9 columnas de tipo int64: Se trata de datos numéricos discretos, como identificadores, límites de velocidad y cantidad de vehículos involucrados en un accidente.\n",
    "14 columnas de tipo object: Contienen valores categóricos y de texto, como nombres de países, días de la semana y tipos de carretera.\n",
    "1 columna de tipo boolean: Representa variables binarias que indican estados verdaderos o falsos, como si el conductor estaba fatigado o no."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El presente análisis tiene como objetivo evaluar las principales características estadísticas de un conjunto de datos. A partir de un resumen estadístico, se busca comprender la distribución de las variables numéricas clave, identificar patrones y evaluar la dispersión de los datos.\n",
    "\n",
    "Este análisis es fundamental para:\n",
    "\n",
    "Comprender la naturaleza de los datos, incluyendo tendencias generales y variabilidad.\n",
    "Identificar valores extremos o atípicos que puedan requerir limpieza o normalización.\n",
    "Evaluar la coherencia y calidad de la información antes de aplicar modelos de predicción o realizar inferencias.\n",
    "\n",
    "Año del incidente: El promedio de los incidentes ocurre en el año 2011, con datos que abarcan desde 2000 hasta 2024, lo que sugiere que el dataset contiene información de múltiples décadas.\n",
    "\n",
    "Visibilidad: La visibilidad promedio en los incidentes es de 275 metros, con una variabilidad alta (desviacion estandar = 129.92), lo que indica escenarios con condiciones climáticas diversas.\n",
    "Límite de velocidad: En promedio, los límites de velocidad en los incidentes registrados son de 74 km/h, con un rango que va desde 30 km/h hasta 119 km/h.\n",
    "Volumen de tráfico: Se observa una media de 5,041 vehículos en el área del accidente, con casos extremos desde 100 hasta 10,000 vehículos, lo que sugiere una cobertura de distintos tipos de vías (desde carreteras secundarias hasta autopistas congestionadas).\n",
    "\n",
    "Número de vehículos involucrados: La mayoría de los incidentes involucran 2 a 3 vehículos, lo que sugiere que predominan colisiones entre automóviles en lugar de accidentes múltiples.\n",
    "Nivel de alcohol en conductores: La media es 0.125 g/dL, lo que sugiere que algunos conductores están bajo la influencia del alcohol, aunque se observan casos con valores cercanos a 0.25 g/dL, que podrían indicar conducción en estado de ebriedad.\n",
    "Peatones y ciclistas involucrados: El número medio de peatones y ciclistas afectados por incidente es cercano a 1, con un máximo de 2 personas, lo que indica que la presencia de estos actores vulnerables es frecuente en los accidentes analizados.\n",
    "\n",
    "Número de heridos: El promedio de personas lesionadas por accidente es 9.5, con casos extremos de hasta 19 heridos, lo que sugiere una alta severidad en los incidentes analizados.\n",
    "Número de fallecidos: La media de 2 muertes por accidente indica la gravedad de ciertos eventos, con valores que alcanzan 4 fallecidos en los peores escenarios.\n",
    "Tiempo de respuesta de emergencia: Los servicios de emergencia tardan un promedio de 32 minutos en llegar, con una variabilidad significativa (desviacion estandar = 15.88), lo que podría influir en la tasa de mortalidad.\n",
    "Reclamos de seguro: Se reporta un promedio de 4.49 reclamos por accidente, con máximos de hasta 9, lo que implica eventos con múltiples víctimas y daños materiales.\n",
    "\n",
    "Costos médicos: Cada accidente genera en promedio $25,198 USD en gastos médicos, lo que resalta la carga económica en el sistema de salud.\n",
    "Pérdidas económicas: El impacto financiero por accidente asciende en promedio a $50,437 USD, con eventos extremos que llegan a los $100,000 USD, lo que demuestra la magnitud del daño económico causado por los incidentes viales.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limpieza"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manejo de Datos Faltantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código verifica la presencia de datos faltantes (valores nulos) en un DataFrame de Pandas. Primero, calcula el número total de valores nulos en el DataFrame. Si este número es cero, se imprime el mensaje \"Datos nulos no encontrados.\", lo que indica que todas las celdas del DataFrame contienen datos válidos. En caso contrario, el código identifica y muestra las columnas que contienen al menos un valor nulo, junto con el número total de valores nulos encontrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "datos_faltantes = df.isnull().sum().sum()\n",
    "\n",
    "if datos_faltantes == 0:\n",
    "    print(\"\\n Datos nulos no encontrados. \")\n",
    "else:\n",
    "    columnas_con_nulos = df.columns[df.isnull().any()].tolist()\n",
    "    print(f\"Columnas con datos nulos: {columnas_con_nulos}\")\n",
    "    print(f\"Numero total de datos nulos: {datos_faltantes}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este caso el print indica que la sumatoria de los valores nulos del dataframe es 0, es decir, que no hay."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manejo de Datos Duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicados=df.duplicated()\n",
    "total_duplicados= duplicados.sum()\n",
    "\n",
    "print(f\"\\n Total de filas duplicadas: {total_duplicados}\")\n",
    "\n",
    "if total_duplicados > 0:\n",
    "    print(\"\\n Filas duplicadas encontradas: \")\n",
    "    print(df[df.duplicated()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El resultado indica que no hay filas duplicadas en el conjunto de datos, lo que significa que cada fila es única y no hay registros repetidos. Esto asegura la integridad de los datos y evita posibles sesgos en el análisis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manejo de datos atípicos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rango Intercuartil (IQR) para detectar valores atípicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = ['speed_limit', 'driver_alcohol_level', 'number_of_vehicles_involved',\n",
    "                  'number_of_injuries', 'number_of_fatalities', 'emergency_response_time',\n",
    "                  'traffic_volume', 'medical_cost', 'economic_loss', 'population_density']\n",
    "\n",
    "for col in numerical_cols:\n",
    "    print(f\"\\n--- Handling Outliers for {col} ---\")\n",
    "\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_limit = Q1 - 1.5 * IQR\n",
    "    upper_limit = Q3 + 1.5 * IQR\n",
    "\n",
    "    outliers = df[(df[col] < lower_limit) | (df[col] > upper_limit)]\n",
    "    print(f\"Number of Outliers: {len(outliers)}\")\n",
    "\n",
    "    df[col] = np.where(df[col] > upper_limit, upper_limit, df[col])\n",
    "    df[col] = np.where(df[col] < lower_limit, lower_limit, df[col])\n",
    "\n",
    "    print(f\"Outliers handled using capping/flooring.\")\n",
    "\n",
    "    \n",
    "    Q1_new = df[col].quantile(0.25)\n",
    "    Q3_new = df[col].quantile(0.75)\n",
    "    IQR_new = Q3_new - Q1_new\n",
    "    lower_limit_new = Q1_new - 1.5 * IQR_new\n",
    "    upper_limit_new = Q3_new + 1.5 * IQR_new\n",
    "\n",
    "    outliers_after = df[(df[col] < lower_limit_new) | (df[col] > upper_limit_new)]\n",
    "    print(f\"Number of Outliers after handling: {len(outliers_after)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El procedimiento aplicado utiliza el Rango Intercuartil (IQR) para detectar valores atípicos en las variables numéricas del conjunto de datos. Se establecieron límites superior e inferior y se reemplazaron los valores que excedieran estos límites mediante el método de capping/flooring. Sin embargo, los resultados indican que no se detectaron valores atípicos en ninguna de las variables analizadas. Esto sugiere que la distribución de los datos es homogénea y no presenta desviaciones extremas que puedan afectar el análisis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conformidad "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Número de cifras decimales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código examina las columnas con tipo de datos 'float' en DataFrame `df` determinando el número máximo de decimales presentes en cada columna para comprender la precisión de los datos. Luego, redondea todos los valores de estas columnas a dos decimales, simplificando los datos y mejorando su legibilidad para análisis y presentación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_float = df.select_dtypes(include=['float'])\n",
    "\n",
    "\n",
    "for col in columnas_float.columns:\n",
    "    max_decimales = columnas_float[col].astype(str).str.split('.').str[1].str.len().max()\n",
    "    print(f\"Número máximo de decimales en la columna '{col}': {max_decimales}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_float_redondeadas = columnas_float.round(2)\n",
    "\n",
    "print(columnas_float_redondeadas.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valores de la columna 'driver_alcohol_level'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los niveles de alcohol en la sangre pueden ser agrupados en categorías significativas (Bajo, Moderado, Alto, etc.) que representan diferentes niveles de riesgo o impacto, en lugar de tratarse como simples valores continuos difíceles de interpretar para el público general. Para esto se utiliza el \"Binning\", que  implica convertir una variable numérica continua en una variable categórica ordinal al agrupar los valores en intervalos o \"bins\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código define una función llamada `categorizar_alcohol_level` que clasifica los niveles de alcohol en la sangre (driver_alcohol_level) en categorías como \"Bajo\", \"Moderado\", \"Alto\", \"Peligroso\" y \"Letal\", basándose en umbrales específicos. Luego, aplica esta función a la columna \"driver_alcohol_level\" del DataFrame df para crear una nueva columna llamada \"Alcohol_Level_Category\", que contiene las categorías correspondientes para cada valor de nivel de alcohol. Finalmente, imprime la columna \"Alcohol_Level_Category\" para mostrar las clasificaciones resultantes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorizar_alcohol_level(driver_alcohol_level):\n",
    "    if driver_alcohol_level < 0.03:\n",
    "        return \"Bajo\"\n",
    "    elif driver_alcohol_level < 0.08:\n",
    "        return \"Moderado\"\n",
    "    elif driver_alcohol_level < 0.20:\n",
    "        return \"Alto\"\n",
    "    elif driver_alcohol_level < 0.30:\n",
    "        return \"Peligroso\"\n",
    "    else:\n",
    "        return \"Letal\"\n",
    "\n",
    "df[\"Alcohol_Level_Category\"] = df[\"driver_alcohol_level\"].apply(categorizar_alcohol_level)\n",
    "\n",
    "print(df[\"Alcohol_Level_Category\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este fragmento de código, se implementa una estrategia de transformación de datos mediante la creación de la función categorize_alcohol_level(driver_alcohol_level), la cual clasifica los valores de la columna driver_alcohol_level en distintas categorías de riesgo: Bajo, Moderado, Alto, Peligroso y Letal. Estas categorías reflejan los efectos del alcohol en la conducción y su impacto potencial en la seguridad vial. Esta conversión no solo optimiza la representación de los datos en visualizaciones, sino que también permite la identificación de patrones clave entre los niveles de alcohol y otros factores críticos, como la severidad de los accidentes o el número de víctimas. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valores de la columna 'visibility_level'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código reemplaza la columna \"visibility_level\" por \"Visibility_Category\", la cual almacena la clasificación correspondiente para cada registro, pasando de un valor numérico a una categoría descriptiva: Muy Baja, Baja, Moderada o Alta. Esto permite transformar una variable numérica en categórica, facilitando la interpretación de los datos y su representación en visualizaciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_visibility(visibility_level):\n",
    "    if visibility_level < 200:\n",
    "        return \"Muy Baja\"\n",
    "    elif visibility_level < 300:\n",
    "        return \"Baja\"\n",
    "    elif visibility_level < 400:\n",
    "        return \"Moderada\"\n",
    "    else:\n",
    "        return \"Alta\"\n",
    "\n",
    "df[\"Visibility_Category\"] = df[\"visibility_level\"].apply(categorize_visibility)\n",
    "\n",
    "print(df[\"Visibility_Category\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valores de \"days_order\", \"months_order\" y \"time_of_day\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nValores únicos en la columna 'time_of_day':\")\n",
    "print(df[\"time_of_day\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las columnas \"day_of_week\", \"month\" y \"time, of day\" son variables categóricas ordinales, lo que significa que las categorías tienen un orden lógico (los días de la semana y los meses del año tienen un orden específico).Al estructurar las variables con un orden definido, se facilita la representación gráfica en gráficos de tendencia o análisis estacionales, evitando errores en la disposición de los datos. Asimismo, esta verificación contribuye a la correcta interpretación de patrones temporales en la ocurrencia de accidentes, lo que puede ser clave para la toma de decisiones en seguridad vial y planificación de estrategias preventivas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código transforma las columnas categóricas \"day_of_week\", \"month\" y \"time_of_day\" en un tipo de dato categórico ordenado en Pandas. Esto permite que el DataFrame conozca el orden lógico de los días de la semana, los meses del año, y el tiempo del día. Se utiliza `pd.Categorical directamente, que es más eficiente y conciso que pd.CategoricalDtype y .astype(). Además, se ha simplificado la impresión de los resultados, eliminando la necesidad de verificar si las columnas están ordenadas, ya que pd.Categorical con ordered=True garantiza que lo estén. Esto facilita el análisis de datos temporales donde el orden es crucial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_order = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "months_order = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "time_of_day_order = [\"Morning\", \"Afternoon\", \"Evening\", \"Night\"]\n",
    "\n",
    "\n",
    "df[\"day_of_week\"] = pd.Categorical(df[\"day_of_week\"], categories=days_order, ordered=True)\n",
    "df[\"month\"] = pd.Categorical(df[\"month\"], categories=months_order, ordered=True)\n",
    "df[\"time_of_day\"] = pd.Categorical(df[\"time_of_day\"], categories=time_of_day_order, ordered=True)\n",
    "\n",
    "print(\"Día de semana (Categórico):\\n\", df[\"day_of_week\"].head(5))\n",
    "print(\"\\nMes (Categórico):\\n\", df[\"month\"].head(5))\n",
    "print(\"\\nTiempo del día (Categórico):\\n\", df[\"time_of_day\"].head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valores únicos de otras columnas con dtype String"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el el método `.unique()` de pandas se identifican y extraen los valores únicos presentes en las columnas driver_fatigue,vehicle_condition, accident_severity, road_type, weather_conditions y driver_gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nValores únicos en la columna 'driver_fatigue':\")\n",
    "print(df[\"driver_fatigue\"].unique())\n",
    "\n",
    "print(\"\\nValores únicos en la columna 'vehicle_condition':\")\n",
    "print(df[\"vehicle_condition\"].unique())\n",
    "\n",
    "print(\"\\nValores únicos en la columna 'accident_severity':\")\n",
    "print(df[\"accident_severity\"].unique())\n",
    "\n",
    "print(\"\\nValores únicos en la columna 'road_type':\")\n",
    "print(df[\"road_type\"].unique())\n",
    "\n",
    "print(\"\\nValores únicos en la columna 'weather_conditions':\")\n",
    "print(df[\"weather_conditions\"].unique())\n",
    "\n",
    "print(\"\\nValores únicos en la columna 'driver_gender':\")\n",
    "print(df[\"driver_gender\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si hubiera variaciones en la forma en que se representan los datos (por ejemplo, \"Male\", \"male\", \"M\"), sería necesario estandarizar los valores. En este caso no hay variaciones en la forma en que se representan los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formato de los enteros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `verificar_enteros(df)` toma un DataFrame de Pandas como entrada y verifica si todas las columnas de tipo entero contienen únicamente valores enteros válidos. Primero, identifica las columnas de tipo entero y luego itera sobre ellas, comprobando si cada columna es realmente de tipo entero y si todos sus valores son instancias de la clase int o np.integer. Si alguna columna no cumple con estas condiciones, la función imprime un mensaje de error y devuelve \"False\"; de lo contrario, devuelve True, indicando que todas las columnas enteras contienen solo valores enteros válidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_enteros(df):\n",
    "\n",
    "    columnas_int = df.select_dtypes(include=['int']).columns\n",
    "\n",
    "    for col in columnas_int:\n",
    "        if not pd.api.types.is_integer_dtype(df[col]):\n",
    "            print(f\"La columna '{col}' no contiene solo valores enteros.\")\n",
    "            return False\n",
    "\n",
    "        if not all(isinstance(x, (int, np.integer)) for x in df[col]):\n",
    "            print(f\"La columna '{col}' contiene valores que no son enteros válidos.\")\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "verificar_enteros(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para las columnas numéricas no hay valores introducidos erróneamente en otro formato."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizaciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grafico de barras por Accidentes por dia de la semana "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "dias_ordenados = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "ax = sns.countplot(\n",
    "    data=df, \n",
    "    x='day_of_week', \n",
    "    order=dias_ordenados,  \n",
    "    palette='Blues', \n",
    "    edgecolor='black', \n",
    "    linewidth=2, \n",
    "    alpha=0.9\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=0, fontsize=12, fontweight='bold')\n",
    "plt.yticks(fontsize=12)\n",
    "plt.title('Accidentes por Día de la Semana', fontsize=16, fontweight='bold', pad=15)\n",
    "plt.xlabel('Día de la Semana', fontsize=13, fontweight='bold', labelpad=10)\n",
    "plt.ylabel('Cantidad de Accidentes', fontsize=13, fontweight='bold', labelpad=10)\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(\n",
    "        f'{p.get_height()}', \n",
    "        (p.get_x() + p.get_width() / 2., p.get_height() + 1), \n",
    "        ha='center', va='bottom', \n",
    "        fontsize=12, fontweight='bold', color='black',\n",
    "        bbox=dict(facecolor='white', edgecolor='none', alpha=0.6)  \n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El gráfico de barras representa la cantidad de accidentes ocurridos en cada día de la semana. Se observa que la distribución de accidentes es relativamente uniforme a lo largo de la semana, con ligeras variaciones entre los días. Los valores oscilan entre aproximadamente 18,000 y 19,000 incidentes diarios, sin una diferencia drástica entre los días laborables y los fines de semana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grafico de barras de Accidentes por condición climática "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "ax = sns.countplot(\n",
    "    data=df, \n",
    "    x='weather_conditions', \n",
    "    order=df['weather_conditions'].value_counts().index, \n",
    "    palette='coolwarm', \n",
    "    edgecolor='black', \n",
    "    linewidth=1.5\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=0, ha='right', fontsize=12, fontweight='bold')\n",
    "plt.yticks(fontsize=12)\n",
    "plt.title('Accidentes por Condición Climática', fontsize=16, fontweight='bold', pad=15)\n",
    "plt.xlabel('Condición Climática', fontsize=13, fontweight='bold', labelpad=10)\n",
    "plt.ylabel('Cantidad de Accidentes', fontsize=13, fontweight='bold', labelpad=10)\n",
    "\n",
    "for p in ax.patches:\n",
    "    ax.annotate(\n",
    "        f'{p.get_height()}', \n",
    "        (p.get_x() + p.get_width() / 2., p.get_height() + 1), \n",
    "        ha='center', va='bottom', \n",
    "        fontsize=12, fontweight='bold', color='black',\n",
    "        bbox=dict(facecolor='white', edgecolor='none', alpha=0.6)  \n",
    "    )\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El gráfico de barras muestra la distribución de accidentes de tráfico según las condiciones climáticas. Se observa que los valores son relativamente homogéneos, con cifras que oscilan entre 26,137 y 26,626 accidentes, con el pico mas alto \"Windy\". A primera vista, esto indica que la climatología no presenta un impacto significativo en la cantidad de accidentes reportados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grafico de tendencias a lo largo de los años"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "sns.lineplot(x=\"year\", y=\"accident_count\", data=df.groupby(\"year\").size().reset_index(name=\"accident_count\"))\n",
    "plt.title(\"Tendencias de los accidentes a lo largo de los años\")\n",
    "plt.xlabel(\"Año\")\n",
    "plt.ylabel(\"Numero de Accidentes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El gráfico de tendencias muestra la evolución del número de accidentes de tráfico desde el año 2000 hasta aproximadamente 2024. A lo largo de este período, se observan fluctuaciones significativas, con picos pronunciados y caídas abruptas, lo que indica que los accidentes no siguen un patrón completamente estable.\n",
    "\n",
    "El pico mas alto ocurre alrededor de 2002-2003, con un notable incremento que supera los 5,400 accidentes. Los descensos más pronunciados se registran alrededor de 2006, 2010 y 2022, donde el número de accidentes cae por debajo de 5,150. A pesar de las fluctuaciones, en la última parte del gráfico se observa una tendencia descendente, lo que indica que los accidentes han disminuido en comparación con los niveles más altos registrados en años anteriores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clasificacion de los dias de la semana "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "weekdays = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\"]\n",
    "weekends = [\"Saturday\", \"Sunday\"]\n",
    "\n",
    "df[\"day_type\"] = df[\"day_of_week\"].apply(lambda x: \"Weekday\" if x in weekdays else \"Weekend\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente fragmento de código tiene como objetivo clasificar los días de la semana en dos categorías: días laborables (Weekdays) y fines de semana (Weekends). Esta clasificación es útil en diversos análisis de datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grafico de torta de los accidentes: dia de semana vs fin de semana "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"white\")\n",
    "\n",
    "accidents_count = df[\"day_type\"].value_counts()\n",
    "\n",
    "colors = [\"#af7ac5\", \"#FFA07A\"]  \n",
    "explode = (0.02, 0.08)  \n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 8))\n",
    "wedges, texts, autotexts = ax.pie(\n",
    "    accidents_count, \n",
    "    labels=accidents_count.index, \n",
    "    autopct='%1.1f%%', \n",
    "    startangle=140, \n",
    "    colors=colors, \n",
    "    explode=explode, \n",
    "    shadow=True, \n",
    "    pctdistance=0.75,  \n",
    "    wedgeprops={'edgecolor': 'black', 'linewidth': 1.5, 'alpha': 0.9}  \n",
    ")\n",
    "\n",
    "for text in texts:\n",
    "    text.set_fontsize(14)\n",
    "    text.set_fontweight(\"bold\")\n",
    "    text.set_color(\"#333\")      \n",
    "\n",
    "for autotexts in autotexts:\n",
    "    autotexts.set_fontsize(14)\n",
    "    autotexts.set_fontweight(\"bold\")\n",
    "    autotexts.set_color(\"white\")\n",
    " \n",
    "plt.title(\"Accidentes: Días de Semana vs. Fines de Semana\", fontsize=18, fontweight=\"bold\", pad=25, color=\"#333\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El gráfico de pastel presentado muestra la distribución de accidentes en función del tipo de día, diferenciando entre días laborables (Weekday) y fines de semana (Weekend). \n",
    "\n",
    "Un 71.4% de los accidentes ocurren de lunes a viernes. Solo un 28.6% de los accidentes se producen los sábados y domingos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Graficos de Boxplot para datos atipicos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "if 'id' in numeric_cols:\n",
    "    numeric_cols = numeric_cols.drop('id')\n",
    "\n",
    "for col in numeric_cols:\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    sns.boxplot(x=df[col], color='skyblue')  \n",
    "    plt.title(f'Boxplot de {col}', fontsize=14)\n",
    "    plt.xlabel('Valores', fontsize=10)\n",
    "    plt.grid(True, axis='x', linestyle='--', alpha=0.6)\n",
    "    plt.xticks(fontsize=8)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "    outliers = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "\n",
    "    if not outliers.empty:\n",
    "        print(f\"Outliers en {col}:\")\n",
    "        print(outliers[[col]])\n",
    "        print(f\"Número de outliers: {len(outliers)}\")\n",
    "        print(\"-\" * 30)\n",
    "    else:\n",
    "        print(f\"No se encontraron outliers en {col}\")\n",
    "        print(\"-\" * 30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código recorre las columnas numéricas de un DataFrame, excluyendo la columna 'id', asociado a cada registro y que no es información original del dataset, y genera un boxplot individual para cada columna. Luego, calcula los límites para detectar valores atípicos (outliers) usando el método del rango intercuartílico (IQR) y los imprime en la consola, junto con el número total de outliers encontrados en cada columna.\n",
    "\n",
    "En el gráfico no se encontraron outliers, por lo que en el dataset no hay datos atípicos, como habíamos mencionado anteriormente. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grafico de la Matriz de Correlacion entre Variables Numéricas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_df = df.select_dtypes(include=['number'])\n",
    "\n",
    "corr_matrix = numeric_df.corr()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(corr_matrix, annot=True, fmt=\".2f\", cmap=\"coolwarm\", linewidths=0.5)\n",
    "\n",
    "plt.title(\"Matriz de Correlación entre Variables Numéricas\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta representación nos permite evaluar la relación lineal entre distintas características de los incidentes, facilitando la identificación de patrones y dependencias entre factores clave en la siniestralidad vial. \n",
    "\n",
    "La matriz indica valores de correlación cercanos a 0 en casi todas las combinaciones de variables, lo que sugiere una independencia estadística entre ellas. Se identifican valores de correlación alta (cercanos a 1) en algunas variables relacionadas. \n",
    "\n",
    "La matriz de correlación evidencia una baja relación lineal entre las variables estudiadas, lo que refuerza la idea de que los accidentes de tráfico son fenómenos complejos, influenciados por múltiples factores simultáneamente."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
