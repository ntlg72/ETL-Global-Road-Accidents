{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f2e2e3f",
   "metadata": {},
   "source": [
    "# EDA API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4633e961",
   "metadata": {},
   "source": [
    "### Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eb8ab248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "sys.path.append(os.path.abspath('../source'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12879588",
   "metadata": {},
   "source": [
    "### Descarga de Datos de Accidentes FARS desde la API de NHTSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "81bab446",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbase_url = \"https://crashviewer.nhtsa.dot.gov/CrashAPI/FARSData/GetFARSData\"\\n\\n# Encabezados\\nheaders = {\\n    \"Accept\": \"text/csv\", \\n    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\\n}\\n\\n\\noutput_dir = \"../data\"\\nos.makedirs(output_dir, exist_ok=True)\\n\\n\\nfor year in range(2017, 2023):  \\n\\n    url = f\"{base_url}?dataset=Accident&FromYear={year}&ToYear={year}&State=*&format=csv\"\\n    print(f\"Descargando datos para el año {year}...\")\\n\\n    try:\\n        # Realizar la solicitud al API\\n        response = requests.get(url, headers=headers, timeout=600, stream=True)  # Timeout de 10 minutos\\n\\n        # Verificar si la solicitud fue exitosa\\n        if response.status_code == 200:\\n            # Guardar los datos en el archivo CSV\\n            output_file = os.path.join(output_dir, f\"FARS_data_{year}.csv\")\\n            with open(output_file, \"wb\") as file:\\n                for chunk in response.iter_content(chunk_size=1024):\\n                    if chunk:\\n                        file.write(chunk)\\n            print(f\"Datos del año {year} guardados exitosamente en {output_file}\")\\n        else:\\n            print(f\"Error al obtener los datos para el año {year}: Código HTTP {response.status_code}\")\\n            print(response.text)\\n\\n    except requests.exceptions.Timeout:\\n        print(f\"La solicitud para el año {year} excedió el tiempo límite.\")\\n    except requests.exceptions.RequestException as e:\\n        print(f\"Error en la solicitud para el año {year}: {e}\")\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "base_url = \"https://crashviewer.nhtsa.dot.gov/CrashAPI/FARSData/GetFARSData\"\n",
    "\n",
    "# Encabezados\n",
    "headers = {\n",
    "    \"Accept\": \"text/csv\", \n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
    "}\n",
    "\n",
    "\n",
    "output_dir = \"../data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "for year in range(2017, 2023):  \n",
    "\n",
    "    url = f\"{base_url}?dataset=Accident&FromYear={year}&ToYear={year}&State=*&format=csv\"\n",
    "    print(f\"Descargando datos para el año {year}...\")\n",
    "\n",
    "    try:\n",
    "        # Realizar la solicitud al API\n",
    "        response = requests.get(url, headers=headers, timeout=600, stream=True)  # Timeout de 10 minutos\n",
    "\n",
    "        # Verificar si la solicitud fue exitosa\n",
    "        if response.status_code == 200:\n",
    "            # Guardar los datos en el archivo CSV\n",
    "            output_file = os.path.join(output_dir, f\"FARS_data_{year}.csv\")\n",
    "            with open(output_file, \"wb\") as file:\n",
    "                for chunk in response.iter_content(chunk_size=1024):\n",
    "                    if chunk:\n",
    "                        file.write(chunk)\n",
    "            print(f\"Datos del año {year} guardados exitosamente en {output_file}\")\n",
    "        else:\n",
    "            print(f\"Error al obtener los datos para el año {year}: Código HTTP {response.status_code}\")\n",
    "            print(response.text)\n",
    "\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(f\"La solicitud para el año {year} excedió el tiempo límite.\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error en la solicitud para el año {year}: {e}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nbase_url = \"https://crashviewer.nhtsa.dot.gov/CrashAPI/FARSData/GetFARSData\"\\n\\n# Encabezados\\nheaders = {\\n    \"Accept\": \"text/csv\", \\n    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\\n}\\n\\noutput_dir = \"../data\"\\nos.makedirs(output_dir, exist_ok=True)\\n\\nfor year in range(2017, 2023):  \\n\\n    url = f\"{base_url}?dataset=Person&FromYear={year}&ToYear={year}&State=*&format=csv\"\\n    print(f\"Descargando datos para el año {year}...\")\\n\\n    try:\\n        # Realizar la solicitud al API\\n        response = requests.get(url, headers=headers, timeout=600, stream=True)  # Timeout de 10 minutos\\n\\n        # Verificar si la solicitud fue exitosa\\n        if response.status_code == 200:\\n            # Guardar los datos en el archivo CSV\\n            output_file = os.path.join(output_dir, f\"FARS_person_{year}.csv\")\\n            with open(output_file, \"wb\") as file:\\n                for chunk in response.iter_content(chunk_size=1024):\\n                    if chunk:\\n                        file.write(chunk)\\n            print(f\"Datos del año {year} guardados exitosamente en {output_file}\")\\n        else:\\n            print(f\"Error al obtener los datos para el año {year}: Código HTTP {response.status_code}\")\\n            print(response.text)\\n\\n    except requests.exceptions.Timeout:\\n        print(f\"La solicitud para el año {year} excedió el tiempo límite.\")\\n    except requests.exceptions.RequestException as e:\\n        print(f\"Error en la solicitud para el año {year}: {e}\")\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "base_url = \"https://crashviewer.nhtsa.dot.gov/CrashAPI/FARSData/GetFARSData\"\n",
    "\n",
    "# Encabezados\n",
    "headers = {\n",
    "    \"Accept\": \"text/csv\", \n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
    "}\n",
    "\n",
    "output_dir = \"../data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for year in range(2017, 2023):  \n",
    "    \n",
    "    url = f\"{base_url}?dataset=Person&FromYear={year}&ToYear={year}&State=*&format=csv\"\n",
    "    print(f\"Descargando datos para el año {year}...\")\n",
    "\n",
    "    try:\n",
    "        # Realizar la solicitud al API\n",
    "        response = requests.get(url, headers=headers, timeout=600, stream=True)  # Timeout de 10 minutos\n",
    "\n",
    "        # Verificar si la solicitud fue exitosa\n",
    "        if response.status_code == 200:\n",
    "            # Guardar los datos en el archivo CSV\n",
    "            output_file = os.path.join(output_dir, f\"FARS_person_{year}.csv\")\n",
    "            with open(output_file, \"wb\") as file:\n",
    "                for chunk in response.iter_content(chunk_size=1024):\n",
    "                    if chunk:\n",
    "                        file.write(chunk)\n",
    "            print(f\"Datos del año {year} guardados exitosamente en {output_file}\")\n",
    "        else:\n",
    "            print(f\"Error al obtener los datos para el año {year}: Código HTTP {response.status_code}\")\n",
    "            print(response.text)\n",
    "\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(f\"La solicitud para el año {year} excedió el tiempo límite.\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error en la solicitud para el año {year}: {e}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1a0442",
   "metadata": {},
   "source": [
    "#### Carga de Datos de Accidentes FARS desde Archivos CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b7e11a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_58825/1353280254.py:10: DtypeWarning: Columns (41,43) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>caseyear</th>\n",
       "      <th>state</th>\n",
       "      <th>st_case</th>\n",
       "      <th>statename</th>\n",
       "      <th>ve_total</th>\n",
       "      <th>ve_forms</th>\n",
       "      <th>pvh_invl</th>\n",
       "      <th>peds</th>\n",
       "      <th>pernotmvit</th>\n",
       "      <th>permvit</th>\n",
       "      <th>...</th>\n",
       "      <th>hosp_mnname</th>\n",
       "      <th>cf1</th>\n",
       "      <th>cf1name</th>\n",
       "      <th>cf2</th>\n",
       "      <th>cf2name</th>\n",
       "      <th>cf3</th>\n",
       "      <th>cf3name</th>\n",
       "      <th>fatals</th>\n",
       "      <th>drunk_dr</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>10001</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Not Applicable (Not Transported)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>10002</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Not Applicable (Not Transported)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>10003</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>Not Applicable (Not Transported)</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>10004</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>Not Applicable (Not Transported)</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Police Pursuit Involved</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017</td>\n",
       "      <td>1</td>\n",
       "      <td>10005</td>\n",
       "      <td>Alabama</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2017</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   caseyear  state  st_case statename  ve_total  ve_forms  pvh_invl  peds  \\\n",
       "0      2017      1    10001   Alabama         1         1         0     0   \n",
       "1      2017      1    10002   Alabama         1         1         0     0   \n",
       "2      2017      1    10003   Alabama         3         3         0     0   \n",
       "3      2017      1    10004   Alabama         1         1         0     0   \n",
       "4      2017      1    10005   Alabama         1         1         0     0   \n",
       "\n",
       "   pernotmvit  permvit  ...                       hosp_mnname   cf1  \\\n",
       "0           0        1  ...  Not Applicable (Not Transported)   0.0   \n",
       "1           0        1  ...  Not Applicable (Not Transported)   0.0   \n",
       "2           0        3  ...  Not Applicable (Not Transported)   0.0   \n",
       "3           0        1  ...  Not Applicable (Not Transported)  20.0   \n",
       "4           0        2  ...                                11   0.0   \n",
       "\n",
       "                   cf1name  cf2 cf2name  cf3  cf3name  fatals drunk_dr  Year  \n",
       "0                      NaN  0.0     NaN  0.0      NaN       1      0.0  2017  \n",
       "1                      NaN  0.0     NaN  0.0      NaN       1      0.0  2017  \n",
       "2                      NaN  0.0     NaN  0.0      NaN       1      0.0  2017  \n",
       "3  Police Pursuit Involved  0.0     NaN  0.0      NaN       1      0.0  2017  \n",
       "4                      NaN  0.0     NaN  0.0      NaN       1      0.0  2017  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir los años a procesar\n",
    "years = range(2017, 2023)  # Desde 2017 hasta 2022\n",
    "\n",
    "# Lista para almacenar DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Cargar archivos en un ciclo\n",
    "for year in years:\n",
    "    file_path = f'../data/FARS_data_{year}.csv'  # Ajusta el path si es necesario\n",
    "    df = pd.read_csv(file_path)\n",
    "    df[\"Year\"] = year  # Agregar la columna de año para referencia\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenar todos los DataFrames en uno solo\n",
    "accidents = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Ver los primeros registros\n",
    "accidents.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cecb75e",
   "metadata": {},
   "source": [
    "Esta celda carga los datos delos accidentes desde archivos CSV para los años 2017 a 2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "313541c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_58825/517759701.py:10: DtypeWarning: Columns (117,119) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/tmp/ipykernel_58825/517759701.py:10: DtypeWarning: Columns (18,117,119) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/tmp/ipykernel_58825/517759701.py:10: DtypeWarning: Columns (18,115,117,119) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/tmp/ipykernel_58825/517759701.py:10: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/tmp/ipykernel_58825/517759701.py:10: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n",
      "/tmp/ipykernel_58825/517759701.py:10: DtypeWarning: Columns (18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(file_path)\n"
     ]
    }
   ],
   "source": [
    "# Años a procesar\n",
    "years = range(2017, 2023)  # Hasta 2022 \n",
    "\n",
    "# Lista para almacenar DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Cargar archivos en un ciclo\n",
    "for year in years:\n",
    "    file_path = f'../data/FARS_person_{year}.csv'  # Ajusta el path si es necesario\n",
    "    df = pd.read_csv(file_path)\n",
    "    df[\"Year\"] = year  # Agregar la columna de año para referencia\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenar todos los DataFrames en uno solo\n",
    "persons = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34ca858a",
   "metadata": {},
   "source": [
    "Esta celda carga los datos de personas involucradas en los accidentes desde archivos CSV para los años 2017 a 2022:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a8c54a",
   "metadata": {},
   "source": [
    "#### Unión de Datos de Accidentes y Persons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4a2bcbee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['caseyear', 'state', 'st_case', 'statename', 've_total', 've_forms',\n",
      "       'pvh_invl', 'peds', 'pernotmvit', 'permvit', 'persons', 'county',\n",
      "       'countyname', 'city', 'cityname', 'day', 'dayname', 'month',\n",
      "       'monthname', 'year', 'day_week', 'day_weekname', 'hour', 'hourname',\n",
      "       'minute', 'minutename', 'nhs', 'nhsname', 'rur_urb', 'rur_urbname',\n",
      "       'func_sys', 'func_sysname', 'rd_owner', 'rd_ownername', 'route',\n",
      "       'routename', 'tway_id', 'tway_id2', 'milept', 'mileptname', 'latitude',\n",
      "       'latitudename', 'longitud', 'longitudname', 'sp_jur', 'sp_jurname',\n",
      "       'harm_ev', 'harm_evname', 'man_coll', 'man_collname', 'reljct1',\n",
      "       'reljct1name', 'reljct2', 'reljct2name', 'typ_int', 'typ_intname',\n",
      "       'wrk_zone', 'wrk_zonename', 'road_fnc', 'road_fncname', 'rel_road',\n",
      "       'rel_roadname', 'lgt_cond', 'lgt_condname', 'weather1', 'weather1name',\n",
      "       'weather2', 'weather2name', 'weather', 'weathername', 'sch_bus',\n",
      "       'sch_busname', 'rail', 'railname', 'not_hour', 'not_hourname',\n",
      "       'not_min', 'not_minname', 'arr_hour', 'arr_hourname', 'arr_min',\n",
      "       'arr_minname', 'hosp_hr', 'hosp_hrname', 'hosp_mn', 'hosp_mnname',\n",
      "       'cf1', 'cf1name', 'cf2', 'cf2name', 'cf3', 'cf3name', 'fatals',\n",
      "       'drunk_dr', 'Year'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(accidents.columns)  # Muestra todas las columnas disponibles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2193682c",
   "metadata": {},
   "source": [
    "imprime los nombres de las columnas del DataFrame accidents para inspeccionar las variables disponibles.\n",
    "\n",
    "La lista de columnas proporciona una visión completa de las variables disponibles en los datos de accidentes, lo que facilita la selección de columnas relevantes para la unión con los datos de personas y el análisis posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5beee087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['caseyear', 'state', 'statename', 'st_case', 've_forms', 'veh_no',\n",
      "       'per_no', 'str_veh', 'str_vehname', 'county',\n",
      "       ...\n",
      "       'icfinalbodyname', 'gvwr_from', 'gvwr_fromname', 'gvwr_to',\n",
      "       'gvwr_toname', 'devtype', 'devtypename', 'devmotor', 'devmotorname',\n",
      "       'Year'],\n",
      "      dtype='object', length=160)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(persons.columns)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b748a0e",
   "metadata": {},
   "source": [
    "imprime los nombres de las columnas del DataFrame persons para inspeccionar las variables disponibles.\n",
    "\n",
    "La gran cantidad de columnas (160) indica que los datos de personas son muy detallados, con información sobre cada individuo involucrado en los accidentes. Columnas como age, sex, y alc_res son clave para el análisis demográfico y de comportamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba946e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = accidents.merge(persons[['st_case', 'age', 'sex', 'alc_res']], on='st_case', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53118fe4",
   "metadata": {},
   "source": [
    "Esta celda combina los DataFrames accidents y persons usando un *merge* por la columna st_case (identificador único del accidente):\n",
    "\n",
    "- Selecciona solo las columnas st_case, age, sex, y alc_res del DataFrame persons.\n",
    "- Usa un *left join* para mantener todos los registros de accidents y agregar la información de personas correspondiente, dejando valores nulos si no hay coincidencia.\n",
    "\n",
    "La unión permite combinar información de accidentes (como condiciones del accidente y fatalidades) con datos demográficos y de alcohol de las personas involucradas, preparando el conjunto de datos para un análisis más detallado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6070cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3984ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b83c04",
   "metadata": {},
   "source": [
    "### Generalidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfeffdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147a73df",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Esta celda muestra el tamaño del DataFrame `df` (3,012,888 filas, 98 columnas)\n",
    "\n",
    "El DataFrame contiene una gran cantidad de datos (más de 3 millones de registros), con un registro por cada persona involucrada en un accidente. Las 98 columnas indican una amplia variedad de variables para analizar."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f442bead",
   "metadata": {},
   "source": [
    "#### Tipos de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "534a2e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324db028",
   "metadata": {},
   "source": [
    "\n",
    "El DataFrame contiene una amplia variedad de datos (numéricos, categóricos y de texto) debido a la mezcla de tipos de datos.\n",
    "\n",
    "- **Tamaño**: 3,012,888 filas y 98 columnas.  \n",
    "- **Tipos de datos**: 47 columnas `int64`, 10 columnas `float64`, 41 columnas `object`.  \n",
    "- **Columnas clave**: `caseyear` (int64), `statename` (object), `latitude` (float64), `age` (int64), `alc_res` (int64).  \n",
    "- **Uso de memoria**: Más de 2.2 GB, lo que indica un conjunto de datos grande.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f33df8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffd7196",
   "metadata": {},
   "source": [
    "### Limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6379eca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    've_total', 'fatals', 'peds','arr_hour', 'arr_min',\n",
    "    'year', 'monthname', 'day_weekname','hour','minute',\n",
    "    'state', 'statename', 'rur_urbname', 'func_sysname', \n",
    "    'weathername', 'lgt_condname','harm_evname',\n",
    "    'age', 'sex', 'alc_res'\n",
    "]\n",
    "\n",
    "df = df[columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92d101e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e3999a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ee5193",
   "metadata": {},
   "source": [
    "#### Manejo de datos de faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18db24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5903db4",
   "metadata": {},
   "source": [
    "#### Manejo de datos duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0842104",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f05581",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9563463",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rur_urbname'].value_counts()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[~df[\"rur_urbname\"].isin([\"Not Reported\", \"Trafficway Not in State Inventory\", \"Unknown\"])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb2f052",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weathername'].value_counts()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d214bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[~df[\"weathername\"].isin([\n",
    "    \"Not Reported\", \"Other\", \"Unknown\", \"Reported as Unknown\"\n",
    "])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "638c6d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f4d80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lgt_condname'].value_counts()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a6e9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[~df['lgt_condname'].isin([\n",
    "    \"Not Reported\", \"Other\", \"Unknown\", \"Reported as Unknown\"\n",
    "])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665d5aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario con códigos especiales por columna\n",
    "special_codes = {\n",
    "    'arr_hour': [88, 99],\n",
    "    'arr_min': [88, 97, 98, 99],\n",
    "}\n",
    "\n",
    "for col, codes in special_codes.items():\n",
    "    df[col] = df[col].replace({code: -1 for code in codes})  # -1 como marcador en lugar de NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[~df[['arr_hour', 'arr_min']].isin([-1]).any(axis=1)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d613639d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Las siguientes variables de tiempo del dataset FARS fueron procesadas para eliminar códigos especiales o valores fuera del rango válido:\n",
    "\n",
    "- `arr_hour`: hora de llegada\n",
    "- `arr_min`: minuto de llegada\n",
    "\n",
    "\n",
    "Estas variables contenían códigos utilizados por el sistema FARS para representar valores especiales:\n",
    "\n",
    "| Código | Significado común en FARS |\n",
    "|--------|----------------------------|\n",
    "| `88`   | Not Applicable             |\n",
    "| `96`   | Anómalo (fuera de rango)   |\n",
    "| `97`   | Imputed                    |\n",
    "| `98`   | Estimated                  |\n",
    "| `99`   | Unknown / Missing          |\n",
    "\n",
    "Estos códigos fueron reemplazados por `-1` y eliminados dado que no eran muchos.\n",
    "\n",
    "Por ejemplo:\n",
    "- `arr_min` contenía valores como `97`, `98`, `99`, que no representan minutos válidos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e528c979",
   "metadata": {},
   "source": [
    "### Manejo de la variable `sex`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f210d43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sex\"].value_counts()[[8, 9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237e9269",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[~df[\"sex\"].isin([\"Not Reported\", \"Unknown\"])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de56e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_mapping = {\n",
    "    1: \"Male\",\n",
    "    2: \"Female\",\n",
    "    3: \"Other\",\n",
    "}\n",
    "\n",
    "df[\"sex\"] = df[\"sex\"].map(sex_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f171f7f",
   "metadata": {},
   "source": [
    "### Manejo de la variable `func_sysname`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8c5e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['func_sysname'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6379df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario con códigos especiales para la columna 'func_sysname'\n",
    "special_codes = {\n",
    "    'func_sysname': ['Not Reported', 'Unknown']  \n",
    "}\n",
    "\n",
    "# Reemplazar valores especiales por -1 como marcador en lugar de NaN\n",
    "for col, codes in special_codes.items():\n",
    "    df[col] = df[col].replace({code: -1 for code in codes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9788f24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar filas donde 'func_sysname' no contenga valores especiales (-1)\n",
    "df = df.loc[~df['func_sysname'].isin([-1])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9822b0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['func_sysname'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3058c89",
   "metadata": {},
   "source": [
    "## Estadísticas descriptivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d01405",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a23702",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62f2a2f",
   "metadata": {},
   "source": [
    "Se presentan estadísticas para columnas numéricas como `ve_total`, `fatals`, `peds`, `arr_hour`, `arr_min`, `year`, `hour`, `minute`, `state`, `age`, `alc_res`:  \n",
    "- **`ve_total` (número de vehículos)**: Media de 1.66, máximo de 50. La mayoría de los accidentes involucran pocos vehículos (1-2).  \n",
    "- **`fatals` (fatalidades)**: Media de 1.10, máximo de 20. La mayoría de los accidentes tienen 1 fatalidad.  \n",
    "- **`peds` (peatones)**: Media de 0.20, máximo de 20. Los peatones están involucrados en pocos casos.  \n",
    "- **`age` (edad)**: Media de 57.70, máximo de 999. Valores como 999 sugieren datos faltantes o \"desconocido\".  \n",
    "- **`alc_res` (nivel de alcohol)**: Media de 632.27, máximo de 999. Muchos valores en 996 indican \"sin prueba de alcohol\".  \n",
    "\n",
    "La mayoría de los accidentes involucran 1-2 vehículos y 1 fatalidad. Los valores atípicos en `age` (999) y `alc_res` (996, 999) indican datos faltantes o codificados como \"desconocido\", lo que requerirá limpieza. La distribución de horas (`hour`, `arr_hour`) muestra que los accidentes ocurren durante todo el día, con un promedio alrededor de las 13:00-14:00."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c2baaa",
   "metadata": {},
   "source": [
    "### Análisis de valores atípicos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0b2c106",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "outlier_log = []\n",
    "\n",
    "for col in numerical_cols:\n",
    "    print(f\"\\n--- Analyzing Outliers for '{col}' ---\")\n",
    "\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_limit = Q1 - 1.5 * IQR\n",
    "    upper_limit = Q3 + 1.5 * IQR\n",
    "\n",
    "    outliers = df[(df[col] < lower_limit) | (df[col] > upper_limit)]\n",
    "    num_outliers = len(outliers)\n",
    "\n",
    "    print(f\"Number of Outliers: {num_outliers}\")\n",
    "    print(f\"Lower Limit: {lower_limit:.2f}, Upper Limit: {upper_limit:.2f}\")\n",
    "\n",
    "    outlier_log.append({\n",
    "        'Variable': col,\n",
    "        'Outliers': num_outliers,\n",
    "        'Lower Limit': lower_limit,\n",
    "        'Upper Limit': upper_limit,\n",
    "        'Porcentaje de Outliers': round(num_outliers / len(df) * 100, 2)\n",
    "    })\n",
    "\n",
    "print(\"\\nResumen de Outliers:\")\n",
    "print(outlier_log)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "740e0790",
   "metadata": {},
   "source": [
    "\n",
    "Los altos porcentajes de atípicos en `fatals` y `peds` indican que los accidentes con múltiples fatalidades o peatones son raros pero relevantes. Los atípicos en `age` y `alc_res` probablemente provienen de valores codificados como \"desconocido\" (999, 996), lo que requiere limpieza para análisis futuros.\n",
    "\n",
    "Se analizaron los valores atípicos en columnas como `ve_total`, `fatals`, `peds`, `arr_hour`, `arr_min`, `year`, `hour`, `minute`, `state`, `age`, `alc_res`:  \n",
    "- **`ve_total` (número de vehículos)**: 37,401 atípicos (2.98%), con un límite superior de 3.5 vehículos.  \n",
    "- **`fatals` (fatalidades)**: 103,454 atípicos (8.25%), con un límite superior de 1. Cualquier accidente con más de 1 fatalidad es atípico.  \n",
    "- **`peds` (peatones)**: 225,024 atípicos (17.94%), con un límite superior de 0. Cualquier accidente con peatones es atípico.  \n",
    "- **`age` (edad)**: 22,747 atípicos (1.81%), con un límite superior de 106.5, probablemente por valores como 999.  \n",
    "- **`alc_res` (nivel de alcohol)**: 0 atípicos, pero esto puede ser engañoso debido a valores codificados como 996 o 999.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbb8b4f",
   "metadata": {},
   "source": [
    "# Transformations for the dimensional modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a19e369",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aa10688",
   "metadata": {},
   "source": [
    "\n",
    "Lista de 20 columnas: ve_total, fatals, peds, arr_hour, arr_min, year, monthname, day_weekname, hour, minute, state, statename, rur_urbname, func_sysname, weathername, lgt_condname, harm_evname, age, sex, alc_res.\n",
    "Interpretación:\n",
    "\n",
    "La lista confirma las columnas disponibles para las transformaciones, incluyendo variables clave para el modelado dimensional como condiciones del accidente, características demográficas, y resultados de alcohol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b36e930",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['statename', 'state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b136be71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lgt_condname\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94f572c",
   "metadata": {},
   "source": [
    "Las categorías reflejan los niveles de iluminación durante los accidentes, desde luz diurna hasta oscuridad sin iluminación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8935d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "visibility_mapping = {\n",
    "    'Daylight': 'Alta',\n",
    "    'Dawn': 'Moderada',\n",
    "    'Dusk': 'Moderada',\n",
    "    'Dark - Lighted': 'Baja',\n",
    "    'Dark - Not Lighted': 'Muy Baja',\n",
    "    'Dark - Unknown Lighting': 'Muy Baja',\n",
    "    'Unknown': 'Unknown',\n",
    "    'Not Reported': 'Unknown',\n",
    "    'Reported as Unknown': 'Unknown',\n",
    "    'Other': 'Unknown'\n",
    "}\n",
    "\n",
    "df[\"lgt_condname\"] = df[\"lgt_condname\"].map(visibility_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa341842",
   "metadata": {},
   "source": [
    "La transformación estandariza las condiciones de iluminación en niveles de visibilidad más interpretables, facilitando el análisis en el modelo dimensional. La agrupación de categorías raras en Unknown reduce la complejidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f943d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['alc_res'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "539719d9",
   "metadata": {},
   "source": [
    "La gran cantidad de valores únicos sugiere que alc_res contiene datos continuos de BAC, junto con códigos especiales (996, 999) para datos faltantes o no reportados. Esto requiere una transformación para categorizar los valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed552c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir el BAC a su valor real en g/dL\n",
    "df['alc_res'] = df['alc_res'] / 1000\n",
    "\n",
    "# Función de clasificación\n",
    "def clasificar_bac(bac):\n",
    "    if bac <= 0.03:\n",
    "        return \"Bajo\"\n",
    "    elif bac <= 0.08:\n",
    "        return \"Moderado\"\n",
    "    elif bac <= 0.20:\n",
    "        return \"Alto\"\n",
    "    elif bac <= 0.40:\n",
    "        return \"Peligroso\"\n",
    "    else:\n",
    "        return \"Letal\"\n",
    "\n",
    "# Aplicar la función\n",
    "df['alc_res'] = df['alc_res'].apply(clasificar_bac)\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c30af9",
   "metadata": {},
   "source": [
    "La transformación convierte los valores numéricos de BAC en categorías interpretables, lo que facilita el análisis en el modelo dimensional. Los valores altos como 996/1000=0.996 se clasifican como Letal, lo que podría indicar la necesidad de revisar los códigos especiales (996, 999) antes de la transformación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fbbf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"weathername\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68e56d9a",
   "metadata": {},
   "source": [
    "Esta celda muestra los valores únicos de la columna weathername (condiciones climáticas) para entender las categorías disponibles.\n",
    "\n",
    "Las categorías reflejan diversas condiciones climáticas que pueden influir en los accidentes. Esto es útil para estandarizar las categorías en el modelado dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4747690",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_map = {\n",
    "    'Clear': 'Clear',\n",
    "    'Rain': 'Rainy',\n",
    "    'Cloudy': 'Windy',\n",
    "    'Fog, Smog, Smoke': 'Foggy',\n",
    "    'Snow': 'Snowy',\n",
    "    'Sleet or Hail': 'Snowy',\n",
    "    'Freezing Rain or Drizzle': 'Rainy',\n",
    "    'Blowing Snow': 'Snowy',\n",
    "    'Blowing Sand, Soil, Dirt': 'Windy',\n",
    "    'Severe Crosswinds': 'Windy',\n",
    "    'Clear': 'Clear',\n",
    "    'Not Reported': 'Unknown',\n",
    "    'Other': 'Unknown',\n",
    "    'Reported as Unknown': 'Unknown'\n",
    "    # 'Unknown' se mantiene igual\n",
    "}\n",
    "\n",
    "# Aplicamos el reemplazo\n",
    "df['weathername'] = df['weathername'].replace(weather_map)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c392d2b4",
   "metadata": {},
   "source": [
    "Esta celda transforma la columna `weathername` mapeando las condiciones climáticas a categorías simplificadas:  \n",
    "- `Clear` → `Clear`  \n",
    "- `Rain`, `Freezing Rain or Drizzle` → `Rainy`  \n",
    "- `Cloudy`, `Blowing Sand, Soil, Dirt`, `Severe Crosswinds` → `Windy`  \n",
    "- `Snow`, `Sleet or Hail`, `Blowing Snow` → `Snowy`  \n",
    "- `Fog`, `Smog`, `Smoke` → `Foggy`  \n",
    "- Otros valores → `Unknown`\n",
    "\n",
    "La transformación simplifica las categorías climáticas al agrupar condiciones similares, facilitando el análisis en el modelo dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8648b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents['arr_hour'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf0cda0",
   "metadata": {},
   "source": [
    "Los valores representan horas del día (0-23), pero incluyen códigos especiales como 99 (probablemente \"desconocido\") y 88 (posiblemente \"no reportado\"). Esto indica la necesidad de limpiar estos valores antes de usarlos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117cf400",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"arr_hour\"] == 99][\"arr_hour\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f294c131",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"arr_hour\"] == 88][\"arr_hour\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a33445",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"arr_min\"].isin([88, 97, 98, 99])][\"arr_hour\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f89168f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['arr_min'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd8e8109",
   "metadata": {},
   "source": [
    "Los valores representan minutos (0-59) sin códigos especiales (88, 97, 98, 99), confirmando que los datos de arr_min son válidos y están listos para transformaciones de tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0c5e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import time\n",
    "\n",
    "# Aseguramos que no haya NaN y convertimos\n",
    "df['arr_hour'] = df['arr_hour'].fillna(0).astype(int)\n",
    "df['arr_min'] = df['arr_min'].fillna(0).astype(int)\n",
    "\n",
    "# Creamos la columna con objetos tipo datetime.time\n",
    "df['arr_time'] = df.apply(lambda row: time(row['arr_hour'], row['arr_min']), axis=1)\n",
    "\n",
    "print(df[['arr_hour', 'arr_min', 'arr_time']])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54757ba7",
   "metadata": {},
   "source": [
    "La creación de arr_time estandariza las horas de llegada en un formato de tiempo, facilitando cálculos posteriores como la diferencia de tiempo entre el accidente y la llegada de servicios de emergencia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52b52bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['minute'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2cf74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3538de00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['hour'].isin([99, 98])]\n",
    "df = df[~df['minute'].isin([99, 98])]\n",
    "\n",
    "# Aseguramos que no haya NaN y convertimos\n",
    "df['hour'] = df['hour'].fillna(0).astype(int)\n",
    "df['minute'] = df['minute'].fillna(0).astype(int)\n",
    "\n",
    "# Creamos la columna con objetos tipo datetime.time\n",
    "df['time'] = df.apply(lambda row: time(row['hour'], row['minute']), axis=1)\n",
    "\n",
    "print(df[['hour', 'minute', 'time']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f32972",
   "metadata": {},
   "source": [
    "La limpieza elimina datos no válidos (98, 99), y la creación de `time` estandariza las horas de los accidentes en un formato de tiempo, preparando los datos para cálculos posteriores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d5b5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['hour'].isin([99, 98])]\n",
    "df = df[~df['minute'].isin([99, 98])]\n",
    "\n",
    "\n",
    "# Función para calcular la diferencia entre dos objetos time\n",
    "def time_diff(t1, t2):\n",
    "    df = df[~df['hour'].isin([99, 98])]\n",
    "df = df[~df['minute'].isin([99, 98])]\n",
    "\n",
    "    # Convertir a datetime con una fecha ficticia\n",
    "    dt1 = datetime(2023, 1, 1, t1.hour, t1.minute, t1.second)\n",
    "    dt2 = datetime(2023, 1, 1, t2.hour, t2.minute, t2.second)\n",
    "    \n",
    "    # Calcular diferencia (arr_time - time)\n",
    "    diff = dt2 - dt1\n",
    "    \n",
    "    # Si arr_time es menor que time, asumir que es del día siguiente\n",
    "    if diff.total_seconds() < 0:\n",
    "        dt2 = datetime(2023, 1, 2, t2.hour, t2.minute, t2.second)  # Día siguiente\n",
    "        diff = dt2 - dt1\n",
    "    \n",
    "    # Convertir la diferencia a horas, minutos, segundos\n",
    "    total_seconds = diff.total_seconds()\n",
    "    hours = int(total_seconds // 3600) % 24  # Tomar módulo 24 para mantener horas en 0-23\n",
    "    minutes = int((total_seconds % 3600) // 60)\n",
    "    seconds = int(total_seconds % 60)\n",
    "    \n",
    "    return time(hours, minutes, seconds)\n",
    "\n",
    "# Manejar valores nulos y calcular la diferencia\n",
    "df['diff_time'] = df.apply(\n",
    "    lambda row: time_diff(row['time'], row['arr_time']) \n",
    "    if pd.notnull(row['time']) and pd.notnull(row['arr_time']) \n",
    "    else None, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(df[['time', 'arr_time', 'diff_time']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9590ce7d",
   "metadata": {},
   "source": [
    "La columna diff_time mide el tiempo de respuesta de los servicios de emergencia, un indicador clave para el análisis de accidentes. La lógica para manejar diferencias negativas asegura que los cálculos sean correctos incluso si la llegada ocurre después de la medianoche."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Función para categorizar la hora\n",
    "def categorize_time(row):\n",
    "    hour = row.hour\n",
    "    if 5 <= hour < 12:\n",
    "        return \"Morning\"\n",
    "    elif 12 <= hour < 17:\n",
    "        return \"Afternoon\"\n",
    "    elif 17 <= hour < 21:\n",
    "        return \"Evening\"\n",
    "    else:\n",
    "        return \"Night\"\n",
    "\n",
    "# Aplicamos la función a la columna time para crear la nueva columna categórica\n",
    "df['time'] = df['time'].apply(categorize_time).astype(\"category\")\n",
    "\n",
    "print(df[['time']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9a6a8cb",
   "metadata": {},
   "source": [
    "Esta celda categoriza la columna `time` (hora del accidente) en momentos del día:  \n",
    "- Define una función `categorize_time` que clasifica la hora:  \n",
    "  - 5:00-11:59 → `Morning`  \n",
    "  - 12:00-16:59 → `Afternoon`  \n",
    "  - 17:00-20:59 → `Evening`  \n",
    "  - Otros (21:00-4:59) → `Night`  \n",
    "- Aplica la función a `time` y convierte el resultado en una columna categórica.  \n",
    "- Muestra la columna `time`.\n",
    "\n",
    "La categorización simplifica el análisis de patrones temporales, permitiendo identificar si los accidentes son más frecuentes en ciertos momentos del día (por ejemplo, noche vs. mañana)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c5c07b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a6c2c38",
   "metadata": {},
   "source": [
    "La lista confirma las transformaciones realizadas (nuevas columnas como arr_time, time, diff_time, time_of_day) y las columnas originales mantenidas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a036037",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['func_sysname'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96568ed",
   "metadata": {},
   "source": [
    "Tabla de correspondencias entre `func_sysname` y los valores únicos en `'road_type'` del modelo dimensional:\n",
    "\n",
    "|  `func_sysname` | Correspondencia con `road_type` |\n",
    "|------------|--------------------------------|\n",
    "| Interstate | Highway                        |\n",
    "| Principal Arterial – Other Freeways and Expressways | Highway |\n",
    "| Principal Arterial – Other | Main Road |\n",
    "| Minor Arterial | Main Road |\n",
    "| Major Collector | Main Road |\n",
    "| Minor Collector | Street |\n",
    "| Local | Street |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "850fa9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario de mapeo entre 'func_sysname' y 'road_type'\n",
    "mapping = {\n",
    "    'Interstate': 'Highway',\n",
    "    'Principal Arterial - Other Freeways and Expressways': 'Highway',\n",
    "    'Principal Arterial - Other': 'Main Road',\n",
    "    'Minor Arterial': 'Main Road',\n",
    "    'Major Collector': 'Main Road',\n",
    "    'Minor Collector': 'Street',\n",
    "    'Local': 'Street'\n",
    "}\n",
    "\n",
    "# Aplicar el mapeo en la columna 'func_sysname'\n",
    "df['func_sysname'] = df['func_sysname'].map(mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76a10602",
   "metadata": {},
   "source": [
    "La transformación simplifica los tipos de carreteras en categorías más generales, facilitando el análisis en el modelo dimensional.\n",
    "\n",
    "- `Interstate`, `Principal Arterial - Other Freeways and Expressways` → `Highway`  \n",
    "- `Principal Arterial - Other`, `Minor Arterial`, `Major Collector` → `Main Road`  \n",
    "- `Minor Collector`, `Local` → `Street`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990fe771",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['func_sysname'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b846a059",
   "metadata": {},
   "source": [
    "La transformación fue exitosa, reduciendo las categorías de func_sysname a tres tipos de carreteras, listos para el modelado dimensional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f874e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"age\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "729238cf",
   "metadata": {},
   "source": [
    "Los valores representan edades reales, pero la presencia de 998 y 999 indica datos faltantes que necesitan limpieza."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9efc68be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimina las filas con edades inválidas (998 y 999)\n",
    "df = df[~df['age'].isin([998, 999])]\n",
    "\n",
    "def map_driver_age(age):\n",
    "    if age < 18:\n",
    "        return '<18'\n",
    "    elif 18 <= age <= 25:\n",
    "        return '18-25'\n",
    "    elif 26 <= age <= 40:\n",
    "        return '26-40'\n",
    "    elif 41 <= age <= 60:\n",
    "        return '41-60'\n",
    "    elif age > 60:\n",
    "        return '61+'\n",
    "\n",
    "df['age'] = df['age'].apply(map_driver_age)\n",
    "\n",
    "print(df['age'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7ed86e",
   "metadata": {},
   "source": [
    "\n",
    "La agrupación de edades en rangos simplifica el análisis demográfico, permitiendo identificar patrones según los grupos etarios en el modelo dimensional.\n",
    "- `<18`: Menores de 18 años  \n",
    "- `18-25`: Jóvenes adultos  \n",
    "- `26-40`: Adultos jóvenes  \n",
    "- `41-60`: Adultos  \n",
    "- `61+`: Adultos mayores  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f86aff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6cd19c",
   "metadata": {},
   "source": [
    "\n",
    "La lista confirma que las transformaciones han añadido columnas como `time_of_day` y `diff_time`, mientras se mantienen las columnas clave para el análisis.\n",
    "Lista de 22 columnas, incluyendo `ve_total`, `fatals`, `peds`, `year`, `monthname`, `day_weekname`, `func_sysname`, `age`, `diff_time`, `time_of_day`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb5ac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_rename_map = {\n",
    "    've_total': 'number_of_vehicles_involved',\n",
    "    'fatals': 'number_of_fatalities',\n",
    "    'peds': 'pedestrians_involved',\n",
    "    'year': 'year',\n",
    "    'monthname': 'month',\n",
    "    'day_weekname': 'day_of_week',\n",
    "    'rur_urbname': 'urban_rural',\n",
    "    'func_sysname': 'road_type',\n",
    "    'weathername': 'weather_conditions',\n",
    "    'lgt_condname': 'visibility_level',\n",
    "    'harm_evname': 'accident_cause',\n",
    "    'age': 'driver_age_group',\n",
    "    'sex': 'driver_gender',\n",
    "    'alc_res': 'driver_alcohol_level',\n",
    "    'diff_time': 'emergency_response_time',\n",
    "    'time': 'time_of_day'\n",
    "}\n",
    "\n",
    "df.rename(columns=column_rename_map, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c6435c2",
   "metadata": {},
   "source": [
    "El renombramiento hace que los nombres de las columnas sean más descriptivos y consistentes con los datos de que provienen de Postgres y para su posterior modelo dimensional, mejorando la claridad para análisis posteriores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c0a230",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08fd4ed7",
   "metadata": {},
   "source": [
    "Lista de 22 columnas, incluyendo number_of_vehicles_involved, number_of_fatalities, driver_age_group, emergency_response_time, time_of_day\n",
    "\n",
    "La lista confirma que las columnas se renombraron correctamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65a45d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['hour','minute', 'arr_hour', 'arr_min', 'arr_time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b074d8",
   "metadata": {},
   "source": [
    "\n",
    "Esta celda elimina columnas temporales (`hour`, `minute`, `arr_hour`, `arr_min`, `arr_time`) que ya no son necesarias tras crear `time_of_day` y `emergency_response_time`.\n",
    "\n",
    "La eliminación reduce la dimensionalidad del DataFrame, manteniendo solo las columnas relevantes para el modelo dimensional.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f8e5437",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72fcf59f",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Lista de 16 columnas: `number_of_vehicles_involved`, `number_of_fatalities`, `pedestrians_involved`, `year`, `month`, `day_of_week`, `urban_rural`, `road_type`, `weather_conditions`, `visibility_level`, `accident_cause`, `driver_age_group`, `driver_gender`, `driver_alcohol_level`, `time_of_day`, `emergency_response_time`.\n",
    "\n",
    "El DataFrame final está listo para el modelado dimensional, con columnas transformadas y nombres descriptivos.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
