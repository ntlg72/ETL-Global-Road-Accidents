{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9f2e2e3f",
   "metadata": {},
   "source": [
    "# EDA API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4633e961",
   "metadata": {},
   "source": [
    "### Importación de librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "eb8ab248",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, time\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "sys.path.append(os.path.abspath('../source'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12879588",
   "metadata": {},
   "source": [
    "### Descarga de Datos de Accidentes FARS desde la API de NHTSA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81bab446",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "base_url = \"https://crashviewer.nhtsa.dot.gov/CrashAPI/FARSData/GetFARSData\"\n",
    "\n",
    "# Encabezados\n",
    "headers = {\n",
    "    \"Accept\": \"text/csv\", \n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
    "}\n",
    "\n",
    "\n",
    "output_dir = \"../data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "for year in range(2017, 2023):  \n",
    "\n",
    "    url = f\"{base_url}?dataset=Accident&FromYear={year}&ToYear={year}&State=*&format=csv\"\n",
    "    print(f\"Descargando datos para el año {year}...\")\n",
    "\n",
    "    try:\n",
    "        # Realizar la solicitud al API\n",
    "        response = requests.get(url, headers=headers, timeout=600, stream=True)  # Timeout de 10 minutos\n",
    "\n",
    "        # Verificar si la solicitud fue exitosa\n",
    "        if response.status_code == 200:\n",
    "            # Guardar los datos en el archivo CSV\n",
    "            output_file = os.path.join(output_dir, f\"FARS_data_{year}.csv\")\n",
    "            with open(output_file, \"wb\") as file:\n",
    "                for chunk in response.iter_content(chunk_size=1024):\n",
    "                    if chunk:\n",
    "                        file.write(chunk)\n",
    "            print(f\"Datos del año {year} guardados exitosamente en {output_file}\")\n",
    "        else:\n",
    "            print(f\"Error al obtener los datos para el año {year}: Código HTTP {response.status_code}\")\n",
    "            print(response.text)\n",
    "\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(f\"La solicitud para el año {year} excedió el tiempo límite.\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error en la solicitud para el año {year}: {e}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cf713d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "base_url = \"https://crashviewer.nhtsa.dot.gov/CrashAPI/FARSData/GetFARSData\"\n",
    "\n",
    "# Encabezados\n",
    "headers = {\n",
    "    \"Accept\": \"text/csv\", \n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64)\"\n",
    "}\n",
    "\n",
    "output_dir = \"../data\"\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "for year in range(2017, 2023):  \n",
    "    \n",
    "    url = f\"{base_url}?dataset=Person&FromYear={year}&ToYear={year}&State=*&format=csv\"\n",
    "    print(f\"Descargando datos para el año {year}...\")\n",
    "\n",
    "    try:\n",
    "        # Realizar la solicitud al API\n",
    "        response = requests.get(url, headers=headers, timeout=600, stream=True)  # Timeout de 10 minutos\n",
    "\n",
    "        # Verificar si la solicitud fue exitosa\n",
    "        if response.status_code == 200:\n",
    "            # Guardar los datos en el archivo CSV\n",
    "            output_file = os.path.join(output_dir, f\"FARS_person_{year}.csv\")\n",
    "            with open(output_file, \"wb\") as file:\n",
    "                for chunk in response.iter_content(chunk_size=1024):\n",
    "                    if chunk:\n",
    "                        file.write(chunk)\n",
    "            print(f\"Datos del año {year} guardados exitosamente en {output_file}\")\n",
    "        else:\n",
    "            print(f\"Error al obtener los datos para el año {year}: Código HTTP {response.status_code}\")\n",
    "            print(response.text)\n",
    "\n",
    "    except requests.exceptions.Timeout:\n",
    "        print(f\"La solicitud para el año {year} excedió el tiempo límite.\")\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error en la solicitud para el año {year}: {e}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d1a0442",
   "metadata": {},
   "source": [
    "#### Carga de Datos de Accidentes FARS desde Archivos CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7e11a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir los años a procesar\n",
    "years = range(2017, 2023)  # Desde 2017 hasta 2022\n",
    "\n",
    "# Lista para almacenar DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Cargar archivos en un ciclo\n",
    "for year in years:\n",
    "    file_path = f'../data/FARS_data_{year}.csv'  # Ajusta el path si es necesario\n",
    "    df = pd.read_csv(file_path)\n",
    "    df[\"Year\"] = year  # Agregar la columna de año para referencia\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenar todos los DataFrames en uno solo\n",
    "accidents = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Ver los primeros registros\n",
    "accidents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "313541c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Años a procesar\n",
    "years = range(2017, 2023)  # Hasta 2022 \n",
    "\n",
    "# Lista para almacenar DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Cargar archivos en un ciclo\n",
    "for year in years:\n",
    "    file_path = f'../data/FARS_person_{year}.csv'  # Ajusta el path si es necesario\n",
    "    df = pd.read_csv(file_path)\n",
    "    df[\"Year\"] = year  # Agregar la columna de año para referencia\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Concatenar todos los DataFrames en uno solo\n",
    "persons = pd.concat(dataframes, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a8c54a",
   "metadata": {},
   "source": [
    "#### Unión de Datos de Accidentes y Persons "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a2bcbee",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(accidents.columns)  # Muestra todas las columnas disponibles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5beee087",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(persons.columns)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba946e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = accidents.merge(persons[['st_case', 'age', 'sex', 'alc_res']], on='st_case', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c6070cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_copy = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3984ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b83c04",
   "metadata": {},
   "source": [
    "### Generalidades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dfeffdcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f442bead",
   "metadata": {},
   "source": [
    "#### Tipos de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "534a2e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f33df8f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffd7196",
   "metadata": {},
   "source": [
    "### Limpieza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6379eca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\n",
    "    've_total', 'fatals', 'peds','arr_hour', 'arr_min',\n",
    "    'year', 'monthname', 'day_weekname','hour','minute',\n",
    "    'state', 'statename', 'rur_urbname', 'func_sysname', \n",
    "    'weathername', 'lgt_condname','harm_evname',\n",
    "    'age', 'sex', 'alc_res'\n",
    "]\n",
    "\n",
    "df = df[columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "92d101e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4e3999a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6ee5193",
   "metadata": {},
   "source": [
    "#### Manejo de datos de faltantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a18db24d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5903db4",
   "metadata": {},
   "source": [
    "#### Manejo de datos duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e0842104",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "55f05581",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9563463",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cb69a361",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "70d9f2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rur_urbname'].value_counts()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d3ded83",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[~df[\"rur_urbname\"].isin([\"Not Reported\", \"Trafficway Not in State Inventory\", \"Unknown\"])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1bb2f052",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['weathername'].value_counts()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4d214bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[~df[\"weathername\"].isin([\n",
    "    \"Not Reported\", \"Other\", \"Unknown\", \"Reported as Unknown\"\n",
    "])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "638c6d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82f4d80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['lgt_condname'].value_counts()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a6e9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[~df['lgt_condname'].isin([\n",
    "    \"Not Reported\", \"Other\", \"Unknown\", \"Reported as Unknown\"\n",
    "])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "665d5aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario con códigos especiales por columna\n",
    "special_codes = {\n",
    "    'arr_hour': [88, 99],\n",
    "    'arr_min': [88, 97, 98, 99],\n",
    "}\n",
    "\n",
    "for col, codes in special_codes.items():\n",
    "    df[col] = df[col].replace({code: -1 for code in codes})  # -1 como marcador en lugar de NaN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8123ffff",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[~df[['arr_hour', 'arr_min']].isin([-1]).any(axis=1)].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d613639d",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Las siguientes variables de tiempo del dataset FARS fueron procesadas para eliminar códigos especiales o valores fuera del rango válido:\n",
    "\n",
    "- `arr_hour`: hora de llegada\n",
    "- `arr_min`: minuto de llegada\n",
    "\n",
    "\n",
    "Estas variables contenían códigos utilizados por el sistema FARS para representar valores especiales:\n",
    "\n",
    "| Código | Significado común en FARS |\n",
    "|--------|----------------------------|\n",
    "| `88`   | Not Applicable             |\n",
    "| `96`   | Anómalo (fuera de rango)   |\n",
    "| `97`   | Imputed                    |\n",
    "| `98`   | Estimated                  |\n",
    "| `99`   | Unknown / Missing          |\n",
    "\n",
    "Estos códigos fueron reemplazados por `-1` y eliminados dado que no eran muchos.\n",
    "\n",
    "Por ejemplo:\n",
    "- `arr_min` contenía valores como `97`, `98`, `99`, que no representan minutos válidos."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e528c979",
   "metadata": {},
   "source": [
    "### Manejo de la variable `sex`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f210d43e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"sex\"].value_counts()[[8, 9]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "237e9269",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.loc[~df[\"sex\"].isin([\"Not Reported\", \"Unknown\"])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "3de56e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "sex_mapping = {\n",
    "    1: \"Male\",\n",
    "    2: \"Female\",\n",
    "    3: \"Other\",\n",
    "}\n",
    "\n",
    "df[\"sex\"] = df[\"sex\"].map(sex_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f171f7f",
   "metadata": {},
   "source": [
    "### Manejo de la variable `func_sysname`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4c8c5e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['func_sysname'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d6379df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario con códigos especiales para la columna 'func_sysname'\n",
    "special_codes = {\n",
    "    'func_sysname': ['Not Reported', 'Unknown']  \n",
    "}\n",
    "\n",
    "# Reemplazar valores especiales por -1 como marcador en lugar de NaN\n",
    "for col, codes in special_codes.items():\n",
    "    df[col] = df[col].replace({code: -1 for code in codes})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9788f24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrar filas donde 'func_sysname' no contenga valores especiales (-1)\n",
    "df = df.loc[~df['func_sysname'].isin([-1])].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "9822b0a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['func_sysname'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3058c89",
   "metadata": {},
   "source": [
    "## Estadísticas descriptivas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "60d01405",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe(include=\"object\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "83a23702",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b0b2c106",
   "metadata": {},
   "outputs": [],
   "source": [
    "numerical_cols = df.select_dtypes(include=['int64', 'float64']).columns\n",
    "\n",
    "outlier_log = []\n",
    "\n",
    "for col in numerical_cols:\n",
    "    print(f\"\\n--- Analyzing Outliers for '{col}' ---\")\n",
    "\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_limit = Q1 - 1.5 * IQR\n",
    "    upper_limit = Q3 + 1.5 * IQR\n",
    "\n",
    "    outliers = df[(df[col] < lower_limit) | (df[col] > upper_limit)]\n",
    "    num_outliers = len(outliers)\n",
    "\n",
    "    print(f\"Number of Outliers: {num_outliers}\")\n",
    "    print(f\"Lower Limit: {lower_limit:.2f}, Upper Limit: {upper_limit:.2f}\")\n",
    "\n",
    "    outlier_log.append({\n",
    "        'Variable': col,\n",
    "        'Outliers': num_outliers,\n",
    "        'Lower Limit': lower_limit,\n",
    "        'Upper Limit': upper_limit,\n",
    "        'Porcentaje de Outliers': round(num_outliers / len(df) * 100, 2)\n",
    "    })\n",
    "\n",
    "print(\"\\nResumen de Outliers:\")\n",
    "print(outlier_log)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dbb8b4f",
   "metadata": {},
   "source": [
    "# Transformations for the dimensional modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3a19e369",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b36e930",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['statename', 'state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b136be71",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"lgt_condname\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a8935d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "visibility_mapping = {\n",
    "    'Daylight': 'Alta',\n",
    "    'Dawn': 'Moderada',\n",
    "    'Dusk': 'Moderada',\n",
    "    'Dark - Lighted': 'Baja',\n",
    "    'Dark - Not Lighted': 'Muy Baja',\n",
    "    'Dark - Unknown Lighting': 'Muy Baja',\n",
    "    'Unknown': 'Unknown',\n",
    "    'Not Reported': 'Unknown',\n",
    "    'Reported as Unknown': 'Unknown',\n",
    "    'Other': 'Unknown'\n",
    "}\n",
    "\n",
    "df[\"lgt_condname\"] = df[\"lgt_condname\"].map(visibility_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a5f943d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['alc_res'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ed552c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir el BAC a su valor real en g/dL\n",
    "df['alc_res'] = df['alc_res'] / 1000\n",
    "\n",
    "# Función de clasificación\n",
    "def clasificar_bac(bac):\n",
    "    if bac <= 0.03:\n",
    "        return \"Bajo\"\n",
    "    elif bac <= 0.08:\n",
    "        return \"Moderado\"\n",
    "    elif bac <= 0.20:\n",
    "        return \"Alto\"\n",
    "    elif bac <= 0.40:\n",
    "        return \"Peligroso\"\n",
    "    else:\n",
    "        return \"Letal\"\n",
    "\n",
    "# Aplicar la función\n",
    "df['alc_res'] = df['alc_res'].apply(clasificar_bac)\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2fbbf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"weathername\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b4747690",
   "metadata": {},
   "outputs": [],
   "source": [
    "weather_map = {\n",
    "    'Clear': 'Clear',\n",
    "    'Rain': 'Rainy',\n",
    "    'Cloudy': 'Windy',\n",
    "    'Fog, Smog, Smoke': 'Foggy',\n",
    "    'Snow': 'Snowy',\n",
    "    'Sleet or Hail': 'Snowy',\n",
    "    'Freezing Rain or Drizzle': 'Rainy',\n",
    "    'Blowing Snow': 'Snowy',\n",
    "    'Blowing Sand, Soil, Dirt': 'Windy',\n",
    "    'Severe Crosswinds': 'Windy',\n",
    "    'Clear': 'Clear',\n",
    "    'Not Reported': 'Unknown',\n",
    "    'Other': 'Unknown',\n",
    "    'Reported as Unknown': 'Unknown'\n",
    "    # 'Unknown' se mantiene igual\n",
    "}\n",
    "\n",
    "# Aplicamos el reemplazo\n",
    "df['weathername'] = df['weathername'].replace(weather_map)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d8648b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "accidents['arr_hour'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "117cf400",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"arr_hour\"] == 99][\"arr_hour\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "f294c131",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"arr_hour\"] == 88][\"arr_hour\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "75a33445",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df[\"arr_min\"].isin([88, 97, 98, 99])][\"arr_hour\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f89168f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['arr_min'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "db0c5e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import time\n",
    "\n",
    "# Aseguramos que no haya NaN y convertimos\n",
    "df['arr_hour'] = df['arr_hour'].fillna(0).astype(int)\n",
    "df['arr_min'] = df['arr_min'].fillna(0).astype(int)\n",
    "\n",
    "# Creamos la columna con objetos tipo datetime.time\n",
    "df['arr_time'] = df.apply(lambda row: time(row['arr_hour'], row['arr_min']), axis=1)\n",
    "\n",
    "print(df[['arr_hour', 'arr_min', 'arr_time']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4b2cf74d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['hour'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "52b52bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['minute'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3538de00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['hour'].isin([99, 98])]\n",
    "df = df[~df['minute'].isin([99, 98])]\n",
    "\n",
    "# Aseguramos que no haya NaN y convertimos\n",
    "df['hour'] = df['hour'].fillna(0).astype(int)\n",
    "df['minute'] = df['minute'].fillna(0).astype(int)\n",
    "\n",
    "# Creamos la columna con objetos tipo datetime.time\n",
    "df['time'] = df.apply(lambda row: time(row['hour'], row['minute']), axis=1)\n",
    "\n",
    "print(df[['hour', 'minute', 'time']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d5b5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[~df['hour'].isin([99, 98])]\n",
    "df = df[~df['minute'].isin([99, 98])]\n",
    "\n",
    "\n",
    "# Ejemplo de DataFrame (reemplaza con tu DataFrame real)\n",
    "df = pd.DataFrame({\n",
    "    'hour': [14, 14, 14, 4, 4, 23],\n",
    "    'minute': [59, 59, 59, 57, 57, 0],\n",
    "    'time': [time(14, 59), time(14, 59), time(14, 59), time(4, 57), time(4, 57), time(23, 0)],\n",
    "    'arr_hour': [15, 15, 15, 5, 5, 2],\n",
    "    'arr_min': [9, 9, 9, 25, 25, 0],\n",
    "    'arr_time': [time(15, 9), time(15, 9), time(15, 9), time(5, 25), time(5, 25), time(2, 0)]\n",
    "})\n",
    "\n",
    "# Función para calcular la diferencia entre dos objetos time\n",
    "def time_diff(t1, t2):\n",
    "    # Convertir a datetime con una fecha ficticia\n",
    "    dt1 = datetime(2023, 1, 1, t1.hour, t1.minute, t1.second)\n",
    "    dt2 = datetime(2023, 1, 1, t2.hour, t2.minute, t2.second)\n",
    "    \n",
    "    # Calcular diferencia (arr_time - time)\n",
    "    diff = dt2 - dt1\n",
    "    \n",
    "    # Si arr_time es menor que time, asumir que es del día siguiente\n",
    "    if diff.total_seconds() < 0:\n",
    "        dt2 = datetime(2023, 1, 2, t2.hour, t2.minute, t2.second)  # Día siguiente\n",
    "        diff = dt2 - dt1\n",
    "    \n",
    "    # Convertir la diferencia a horas, minutos, segundos\n",
    "    total_seconds = diff.total_seconds()\n",
    "    hours = int(total_seconds // 3600) % 24  # Tomar módulo 24 para mantener horas en 0-23\n",
    "    minutes = int((total_seconds % 3600) // 60)\n",
    "    seconds = int(total_seconds % 60)\n",
    "    \n",
    "    return time(hours, minutes, seconds)\n",
    "\n",
    "# Manejar valores nulos y calcular la diferencia\n",
    "df['diff_time'] = df.apply(\n",
    "    lambda row: time_diff(row['time'], row['arr_time']) \n",
    "    if pd.notnull(row['time']) and pd.notnull(row['arr_time']) \n",
    "    else None, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(df[['time', 'arr_time', 'diff_time']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0c5c07b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6a036037",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['func_sysname'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e96568ed",
   "metadata": {},
   "source": [
    "Tabla de correspondencias entre `func_sysname` y los valores únicos en `'road_type'` del modelo dimensional:\n",
    "\n",
    "|  `func_sysname` | Correspondencia con `road_type` |\n",
    "|------------|--------------------------------|\n",
    "| Interstate | Highway                        |\n",
    "| Principal Arterial – Other Freeways and Expressways | Highway |\n",
    "| Principal Arterial – Other | Main Road |\n",
    "| Minor Arterial | Main Road |\n",
    "| Major Collector | Main Road |\n",
    "| Minor Collector | Street |\n",
    "| Local | Street |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "850fa9d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diccionario de mapeo entre 'func_sysname' y 'road_type'\n",
    "mapping = {\n",
    "    'Interstate': 'Highway',\n",
    "    'Principal Arterial - Other Freeways and Expressways': 'Highway',\n",
    "    'Principal Arterial - Other': 'Main Road',\n",
    "    'Minor Arterial': 'Main Road',\n",
    "    'Major Collector': 'Main Road',\n",
    "    'Minor Collector': 'Street',\n",
    "    'Local': 'Street'\n",
    "}\n",
    "\n",
    "# Aplicar el mapeo en la columna 'func_sysname'\n",
    "df['func_sysname'] = df['func_sysname'].map(mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "9196207c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['func_sysname'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1f874e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"age\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9efc68be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Elimina las filas con edades inválidas (998 y 999)\n",
    "df = df[~df['age'].isin([998, 999])]\n",
    "\n",
    "def map_driver_age(age):\n",
    "    if age < 18:\n",
    "        return '<18'\n",
    "    elif 18 <= age <= 25:\n",
    "        return '18-25'\n",
    "    elif 26 <= age <= 40:\n",
    "        return '26-40'\n",
    "    elif 41 <= age <= 60:\n",
    "        return '41-60'\n",
    "    elif age > 60:\n",
    "        return '61+'\n",
    "\n",
    "df['age'] = df['age'].apply(map_driver_age)\n",
    "\n",
    "print(df['age'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "2f86aff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "beb5ac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "column_rename_map = {\n",
    "    've_total': 'number_of_vehicles_involved',\n",
    "    'fatals': 'number_of_fatalities',\n",
    "    'peds': 'pedestrians_involved',\n",
    "    'year': 'year',\n",
    "    'monthname': 'month',\n",
    "    'day_weekname': 'day_of_week',\n",
    "    'rur_urbname': 'urban_rural',\n",
    "    'func_sysname': 'road_type',\n",
    "    'weathername': 'weather_conditions',\n",
    "    'lgt_condname': 'visibility_level',\n",
    "    'harm_evname': 'accident_cause',\n",
    "    'age': 'driver_age_group',\n",
    "    'sex': 'driver_gender',\n",
    "    'alc_res': 'driver_alcohol_level',\n",
    "    'diff_time': 'emergency_response_time',\n",
    "}\n",
    "\n",
    "df.rename(columns=column_rename_map, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f8c0a230",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "65a45d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['hour','minute', 'arr_hour', 'arr_min', 'time', 'arr_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "4f8e5437",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
