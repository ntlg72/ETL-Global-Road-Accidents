{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformación y Carga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importación de librerías"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Del paquete \"connection_db\", ubicado en el directorio \"source del directorio\", se importa el módulo \"db_utils\" que proporciona una funciones centralizada para establecer y gestionar conexiones a una base de datos PostgreSQL. Su objetivo es promover la reutilización de código, la modularidad y la consistencia en el acceso a la base de datos dentro de los diferentes notebooks de este proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from psycopg2 import sql\n",
    "from sqlalchemy import create_engine\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(os.path.abspath('../source'))\n",
    "from connection_db.db_utils import get_connection , close_connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conexión a la base de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "Este fragmento de código establece una conexión a una base de datos PostgreSQL utilizando la función \"get_connection\" del módulo \"connection_db.db_utils\", lee todos los datos de la tabla \"accidents\" en un DataFrame de Pandas, muestra las primeras filas del DataFrame y luego cierra la conexión a la base de datos utilizando la función \"close_connection\" del mismo módulo, para liberar recursos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = get_connection()\n",
    "df = pd.read_sql_query(\"SELECT * FROM accidents\", engine)\n",
    "df.head()\n",
    "close_connection(engine)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminación de columnas redundantes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código utiliza la función `unique()` de Pandas para identificar y mostrar los valores únicos presentes en las columnas \"country\" y \"region\" del DataFrame `df`. Primero, imprime los valores únicos de la columna \"country\", seguido de un salto de línea y los valores únicos de la columna \"region\". Esto permite inspeccionar rápidamente las categorías o valores distintos presentes en estas columnas, lo cual es útil para comprender la distribución de los datos de estás columnas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Valores únicos en la columna 'country':\")\n",
    "print(df[\"country\"].unique())\n",
    "\n",
    "print(\"\\nValores únicos en la columna 'region':\")\n",
    "print(df[\"region\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"region\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La columna \"region\" ha sido eliminada del dataset, ya que no aporta información relevante para los objetivos del proyecto. Dado que ya contamos con la columna \"country\", la cual especifica el país donde ocurrió cada accidente, la variable \"region\" se vuelve redundante. Además, el nivel de detalle que proporciona la columna de país es más preciso y útil para el análisis, mientras que la región o continente es una categorización más amplia que no aporta valor significativo a nuestro estudio. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conformidad "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Número de cifras decimales"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El código examina las columnas con tipo de datos 'float' en DataFrame `df` determinando el número máximo de decimales presentes en cada columna para comprender la precisión de los datos. Luego, redondea todos los valores de estas columnas a dos decimales, simplificando los datos y mejorando su legibilidad para análisis y presentación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_float = df.select_dtypes(include=['float'])\n",
    "\n",
    "\n",
    "for col in columnas_float.columns:\n",
    "    max_decimales = columnas_float[col].astype(str).str.split('.').str[1].str.len().max()\n",
    "    print(f\"Número máximo de decimales en la columna '{col}': {max_decimales}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_float_redondeadas = columnas_float.round(2)\n",
    "\n",
    "print(columnas_float_redondeadas.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valores de la columna 'driver_alcohol_level'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los niveles de alcohol en la sangre pueden ser agrupados en categorías significativas (Bajo, Moderado, Alto, etc.) que representan diferentes niveles de riesgo o impacto, en lugar de tratarse como simples valores continuos difíceles de interpretar para el público general. Para esto se utiliza el \"Binning\", que  implica convertir una variable numérica continua en una variable categórica ordinal al agrupar los valores en intervalos o \"bins\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código define una función llamada `categorizar_alcohol_level` que clasifica los niveles de alcohol en la sangre (driver_alcohol_level) en categorías como \"Bajo\", \"Moderado\", \"Alto\", \"Peligroso\" y \"Letal\", basándose en umbrales específicos. Luego, aplica esta función a la columna \"driver_alcohol_level\" del DataFrame `df` para crear una nueva columna llamada \"Alcohol_Level_Category\", que contiene las categorías correspondientes para cada valor de nivel de alcohol. Finalmente, imprime la columna \"Alcohol_Level_Category\" para mostrar las clasificaciones resultantes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorizar_alcohol_level(driver_alcohol_level):\n",
    "    if driver_alcohol_level < 0.03:\n",
    "        return \"Bajo\"\n",
    "    elif driver_alcohol_level < 0.08:\n",
    "        return \"Moderado\"\n",
    "    elif driver_alcohol_level < 0.20:\n",
    "        return \"Alto\"\n",
    "    elif driver_alcohol_level < 0.30:\n",
    "        return \"Peligroso\"\n",
    "    else:\n",
    "        return \"Letal\"\n",
    "\n",
    "df[\"Alcohol_Level_Category\"] = df[\"driver_alcohol_level\"].apply(categorizar_alcohol_level)\n",
    "\n",
    "print(df[\"Alcohol_Level_Category\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta conversión no solo optimiza la representación de los datos en visualizaciones, sino que también permite la identificación de patrones clave entre los niveles de alcohol y otros factores críticos, como la severidad de los accidentes o el número de víctimas. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valores de la columna 'visibility_level'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `categorize_visibility` reemplaza la columna \"visibility_level\" por \"Visibility_Category\", la cual almacena la clasificación correspondiente para cada registro, pasando de un valor numérico a una categoría descriptiva: Muy Baja, Baja, Moderada o Alta. Esto permite transformar una variable numérica en categórica, facilitando la interpretación de los datos y su representación en visualizaciones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_visibility(visibility_level):\n",
    "    if visibility_level < 200:\n",
    "        return \"Muy Baja\"\n",
    "    elif visibility_level < 300:\n",
    "        return \"Baja\"\n",
    "    elif visibility_level < 400:\n",
    "        return \"Moderada\"\n",
    "    else:\n",
    "        return \"Alta\"\n",
    "\n",
    "df[\"Visibility_Category\"] = df[\"visibility_level\"].apply(categorize_visibility)\n",
    "\n",
    "print(df[\"Visibility_Category\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valores de \"days_order\", \"months_order\" y \"time_of_day\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nValores únicos en la columna 'time_of_day':\")\n",
    "print(df[\"time_of_day\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Las columnas \"day_of_week\", \"month\" y \"time, of day\" son variables categóricas ordinales, lo que significa que las categorías tienen un orden lógico (los días de la semana y los meses del año tienen un orden específico).Al estructurar las variables con un orden definido, se facilita la representación gráfica en gráficos de tendencia o análisis estacionales, evitando errores en la disposición de los datos. Asimismo, esta verificación contribuye a la correcta interpretación de patrones temporales en la ocurrencia de accidentes, lo que puede ser clave para la toma de decisiones en seguridad vial y planificación de estrategias preventivas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este código transforma las columnas categóricas \"day_of_week\", \"month\" y \"time_of_day\" en un tipo de dato categórico ordenado en Pandas. Esto permite que el DataFrame conozca el orden lógico de los días de la semana, los meses del año, y el tiempo del día. Se utiliza `pd.Categorical directamente, que es más eficiente y conciso que pd.CategoricalDtype y .astype(). Además, se ha simplificado la impresión de los resultados, eliminando la necesidad de verificar si las columnas están ordenadas, ya que pd.Categorical con ordered=True garantiza que lo estén. Esto facilita el análisis de datos temporales donde el orden es crucial.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "days_order = [\"Monday\", \"Tuesday\", \"Wednesday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"]\n",
    "months_order = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \"July\", \"August\", \"September\", \"October\", \"November\", \"December\"]\n",
    "time_of_day_order = [\"Morning\", \"Afternoon\", \"Evening\", \"Night\"]\n",
    "\n",
    "\n",
    "df[\"day_of_week\"] = pd.Categorical(df[\"day_of_week\"], categories=days_order, ordered=True)\n",
    "df[\"month\"] = pd.Categorical(df[\"month\"], categories=months_order, ordered=True)\n",
    "df[\"time_of_day\"] = pd.Categorical(df[\"time_of_day\"], categories=time_of_day_order, ordered=True)\n",
    "\n",
    "print(\"Día de semana (Categórico):\\n\", df[\"day_of_week\"].head(5))\n",
    "print(\"\\nMes (Categórico):\\n\", df[\"month\"].head(5))\n",
    "print(\"\\nTiempo del día (Categórico):\\n\", df[\"time_of_day\"].head(5))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Valores únicos de otras columnas con dtype String"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con el el método `.unique()` de pandas se identifican y extraen los valores únicos presentes en las columnas driver_fatigue,vehicle_condition, accident_severity, road_type, weather_conditions y driver_gender."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nValores únicos en la columna 'driver_fatigue':\")\n",
    "print(df[\"driver_fatigue\"].unique())\n",
    "\n",
    "print(\"\\nValores únicos en la columna 'vehicle_condition':\")\n",
    "print(df[\"vehicle_condition\"].unique())\n",
    "\n",
    "print(\"\\nValores únicos en la columna 'accident_severity':\")\n",
    "print(df[\"accident_severity\"].unique())\n",
    "\n",
    "print(\"\\nValores únicos en la columna 'road_type':\")\n",
    "print(df[\"road_type\"].unique())\n",
    "\n",
    "print(\"\\nValores únicos en la columna 'weather_conditions':\")\n",
    "print(df[\"weather_conditions\"].unique())\n",
    "\n",
    "print(\"\\nValores únicos en la columna 'driver_gender':\")\n",
    "print(df[\"driver_gender\"].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si hubiera variaciones en la forma en que se representan los datos (por ejemplo, \"Male\", \"male\", \"M\"), sería necesario estandarizar los valores. En este caso no hay variaciones en la forma en que se representan los datos. Sin embargo, la columna \"driver_fatigue\" presenta valores binarios (0,1) por lo que es óptimo convertirla a dtype booleano usando `.astype(bool)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"driver_fatigue\"] = df[\"driver_fatigue\"].astype(bool)\n",
    "\n",
    "print(df[\"driver_fatigue\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conexión a la base de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eliminación de columnas redundantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Valores únicos en la columna 'country':\")\n",
    "print(df[\"country\"].unique())\n",
    "\n",
    "print(\"\\nValores únicos en la columna 'region':\")\n",
    "print(df[\"region\"].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3     True\n",
      "4     True\n",
      "Name: driver_fatigue, dtype: bool\n"
     ]
    }
   ],
   "source": [
    "df[\"driver_fatigue\"] = df[\"driver_fatigue\"].astype(bool)\n",
    "\n",
    "print(df[\"driver_fatigue\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Formato de los enteros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función `verificar_enteros(df)` toma un DataFrame de Pandas como entrada y verifica si todas las columnas de tipo entero contienen únicamente valores enteros válidos. Primero, identifica las columnas de tipo entero y luego itera sobre ellas, comprobando si cada columna es realmente de tipo entero y si todos sus valores son instancias de la clase int o np.integer. Si alguna columna no cumple con estas condiciones, la función imprime un mensaje de error y devuelve \"False\"; de lo contrario, devuelve True, indicando que todas las columnas enteras contienen solo valores enteros válidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verificar_enteros(df):\n",
    "\n",
    "    columnas_int = df.select_dtypes(include=['int']).columns\n",
    "\n",
    "    for col in columnas_int:\n",
    "        if not pd.api.types.is_integer_dtype(df[col]):\n",
    "            print(f\"La columna '{col}' no contiene solo valores enteros.\")\n",
    "            return False\n",
    "\n",
    "        if not all(isinstance(x, (int, np.integer)) for x in df[col]):\n",
    "            print(f\"La columna '{col}' contiene valores que no son enteros válidos.\")\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "verificar_enteros(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para las columnas numéricas no hay valores introducidos erróneamente en otro formato."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
