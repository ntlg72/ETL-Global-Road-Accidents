# ğŸš¦ **Pipeline ETL para AnÃ¡lisis de Accidentes Viales Globales**

Este proyecto proporciona un pipeline **ETL completo** para procesar y analizar datos de accidentes viales globales, utilizando datos del dataset de Kaggle ["Global Road Accidents Data"](https://www.kaggle.com/datasets/sobhanmoosavi/us-accidents) y de la **API FARS (Fatality Analysis Reporting System)**. Se emplean herramientas modernas como:

- ğŸ›°ï¸ **Kafka** para streaming de datos  
- ğŸ› ï¸ **Apache Airflow** para orquestaciÃ³n de flujos  
- ğŸ˜ **PostgreSQL** para almacenamiento  
- ğŸ³ **Docker** para contenedores  

---

## ğŸ“‹ Requisitos Previos

- ğŸ³ Docker `>= 20.10.0`  
- ğŸ“¦ Docker Compose `>= 1.29.0`  
- ğŸ§¬ Git  
- ğŸ Python `>= 3.9`  
- ğŸ““ Jupyter Notebook (para los cuadernos de anÃ¡lisis)

---

## ğŸš€ ConfiguraciÃ³n Inicial

### 1. Clonar el Repositorio

```bash
git clone https://github.com/ntlg72/ETL-Global-Road-Accidents.git
cd ETL-Global-Road-Accidents
```

### 2. Configurar Variables de Entorno

Crea un archivo `.env` en la raÃ­z del proyecto con el siguiente contenido:

```env
# ConfiguraciÃ³n de Postgres
PG_PASSWORD=tu_contraseÃ±a_segura
PG_DATABASE=road_accidents
PG_DATABASE_DIMENSIONAL=road_accidents_dimensional
PG_DATABASE_KAFKA=road_accidents_kafka
PG_PORT=5433

# ConfiguraciÃ³n de Airflow
AIRFLOW_UID=50000
AIRFLOW_GID=0
_AIRFLOW_WWW_USER_USERNAME=admin
_AIRFLOW_WWW_USER_PASSWORD=admin
```

### 3. Estructura del Proyecto

```
ETL-Global-Road-Accidents/
â”œâ”€â”€ dags/                  # DAGs de Airflow
â”œâ”€â”€ data/                  # Datos sin procesar y procesados
â”œâ”€â”€ kafka_utils/           # Utilidades para Kafka
â”œâ”€â”€ notebooks/             # Cuadernos de Jupyter para anÃ¡lisis
â”œâ”€â”€ postgres/              # Scripts de inicializaciÃ³n de PostgreSQL
â”œâ”€â”€ source/                # CÃ³digo fuente del proyecto
â”œâ”€â”€ unit_tests/            # Pruebas unitarias
â”œâ”€â”€ .gitattributes
â”œâ”€â”€ .gitignore
â”œâ”€â”€ Dashboard.pdf          # Dashboard generado
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ README.md
â”œâ”€â”€ consumer.py            # Servicio consumidor de Kafka
â”œâ”€â”€ docker-compose.yaml
â”œâ”€â”€ requirements.txt
â””â”€â”€ requirements_docker.txt

```

---

## ğŸ§± ConstrucciÃ³n y EjecuciÃ³n de Servicios

### 4. Levantar los Servicios

```bash
docker-compose up -d --build
```

Esto iniciarÃ¡:

- ğŸ˜ PostgreSQL  
- ğŸ“¡ Zookeeper + Kafka  
- ğŸ”„ Redis (broker para Airflow)  
- ğŸŒ¬ï¸ Apache Airflow (scheduler, webserver, worker)  
- ğŸ Servicio `consumer.py`

---

## ğŸ“Š AnÃ¡lisis y ExtracciÃ³n de Datos

### 5. Ejecutar el Notebook de ExtracciÃ³n

```bash
cd ETL-Global-Road-Accidents/notebooks
pip install jupyter
jupyter notebook
```
ğŸ” **Verifica:**
- Que Kafka y PostgreSQL estÃ©n funcionando  
- Que las conexiones a las bases de datos estÃ©n activas

---

## ğŸŒ Acceso a los Servicios

| Servicio             | URL/Puerto              | Credenciales     |
|----------------------|--------------------------|------------------|
| ğŸŒ¬ï¸ Airflow Web UI    | http://localhost:8080     | admin / admin    |
| ğŸŒ¼ Flower (Celery)   | http://localhost:5555     | -                |
| ğŸ“¡ Kafka             | localhost:9092           | -                |
| ğŸ˜ PostgreSQL        | localhost:5433           | `.env` variables |
| ğŸ Consumer API      | http://localhost:8000     | -                |

---

## ğŸ” Iniciar Proceso ETL

1. Accede a Airflow en: [http://localhost:8080](http://localhost:8080)  
2. Busca y activa el DAG `etl_accidents_pipeline`  
3. Monitorea el progreso en la interfaz de Airflow o usando:

```bash
docker logs consumer -f
```

---

## ğŸš¦ Dashboard en Tiempo Real

Este proyecto incluye un **dashboard interactivo en tiempo real** construido con **Dash** para visualizar dinÃ¡micamente los datos de accidentes viales conforme se actualizan.

### â–¶ï¸ CÃ³mo ejecutar el dashboard

Ejecuta el siguiente comando desde la raÃ­z del proyecto:

bash

CopiarEditar

`python source/real_time_dash.py` 

### ğŸŒ Acceso al dashboard

Abre tu navegador y visita la siguiente URL para ver el dashboard en acciÃ³n:

[http://localhost:8050/](http://localhost:8050/)

AquÃ­ encontrarÃ¡s:

-   KPIs clave actualizÃ¡ndose cada 2 segundos
    
-   GrÃ¡fica interactiva que muestra la evoluciÃ³n del nÃºmero de vehÃ­culos involucrados en accidentes
    

### âš ï¸ Consideraciones importantes

-   AsegÃºrate de que el servicio **consumer** y la API estÃ©n activos en `http://localhost:8000`, ya que el dashboard depende de esta fuente para obtener los datos en tiempo real.
    
-   El dashboard se refresca automÃ¡ticamente cada 2 segundos para mostrar la informaciÃ³n mÃ¡s reciente.

## ğŸ§  CrÃ©ditos

Proyecto desarrollado por:

- ğŸ‘¨â€ğŸ’» Michel Burgos Santos  
- ğŸ‘¨â€ğŸ’» Juan David Daza Rivera  
- ğŸ‘©â€ğŸ’» Natalia LÃ³pez Gallego

---
